# SQL & dbt ハンズオンレクチャー 説明資料（初心者コース）

## 目次

1. [イントロダクション](#イントロダクション)
2. [初心者コース](#初心者コース)
   - [1コマ目：SQL基礎＋応用エッセンス](#初心者コース1コマ目sql基礎応用エッセンス45分)
   - [2コマ目：dbt入門 -「5つの壁」を突破](#初心者コース2コマ目dbt入門5つの壁を突破45分)
3. [Q&A想定集](#qa想定集)

---

## イントロダクション

### ハンズオンの目的

本ハンズオンでは、Webアクセスログ分析をテーマに、SQLとdbtの実践的なスキルを習得します。

### コース構成

| コース | 対象者 | 前提知識 | 学ぶこと |
|--------|--------|----------|----------|
| **初心者コース**（90分） | SQL未経験〜初心者 | なし | SQL基礎＋応用エッセンス + dbt入門 |

**初心者コースの特徴**：1コマ目でSQL基礎に加えてCTE・VIEW・SP・Taskのエッセンスを体験し、「SQLだけでは解決しにくい5つの壁」を認識します。2コマ目でdbtがそれらの壁をどう解決するかを体験します。

---

# 初心者コース

## 前提知識
- なし（SQL未経験でもOK）

## 学ぶこと
- SQLの基本操作（SELECT, JOIN, GROUP BY）
- SQLの応用技術のエッセンス（CTE, VIEW, ストアドプロシジャ, Task）
- **SQLだけでは解決しにくい「5つの壁」**の認識
- dbtの基本概念（モデル、ref、テスト、Lineage）
- dbtが「5つの壁」をどう解決するか

---

## 初心者コース・1コマ目：SQL基礎＋応用エッセンス（45分）

### Step A：SQL基礎ダイジェスト（12分）【ハンズオン】

**目的**：SELECT / WHERE / JOIN / GROUP BY の基本を短時間で体験

#### SELECT + WHERE + DISTINCT（3分）

```sql
-- データの確認
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS LIMIT 10;

-- 条件でフィルタリング
SELECT
    EVENT_ID, USER_ID, EVENT_TYPE, EVENT_TIMESTAMP, COUNTRY
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
WHERE EVENT_TYPE = 'purchase'
  AND COUNTRY IN ('US', 'JP')
LIMIT 20;

-- ユニークな値を確認
SELECT DISTINCT EVENT_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
ORDER BY EVENT_TYPE;
```

**ポイント**：
- `SELECT *` は避け、必要なカラムだけ指定
- `WHERE` で条件を絞る（AND / IN で複数条件）
- `DISTINCT` でユニーク値を確認 → データ品質チェックの第一歩

#### JOIN（4分）

```sql
-- INNER JOIN：イベントログにユーザー属性を結合
SELECT
    E.EVENT_ID, E.USER_ID, E.EVENT_TYPE, E.EVENT_TIMESTAMP,
    U.COUNTRY, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE E.EVENT_TYPE = 'purchase'
LIMIT 20;

-- LEFT JOIN：マッチしないレコードを検出（データ品質チェック）
SELECT E.EVENT_ID, E.USER_ID, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
LEFT JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE U.USER_ID IS NULL
LIMIT 20;
```

**JOIN種別**：
- `INNER JOIN`：両テーブルに存在するレコードのみ
- `LEFT JOIN`：左テーブルの全レコード（マッチしない場合はNULL）

#### GROUP BY + 集計関数（4分）

```sql
-- 日別のイベント数を集計
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP)
ORDER BY EVENT_DATE DESC;

-- CASE文で条件付き集計
SELECT
    U.COUNTRY,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(CASE WHEN E.EVENT_TYPE = 'page_view' THEN 1 END) AS PAGEVIEW_COUNT,
    COUNT(CASE WHEN E.EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
GROUP BY U.COUNTRY
ORDER BY TOTAL_EVENTS DESC;
```

**ポイント**：
- `GROUP BY` で同じ値を持つ行をグループ化して集計
- `COUNT(*)` は全行数、`COUNT(DISTINCT ...)` はユニーク数
- `CASE` 文で条件付き集計 → ファネル分析の基礎

#### Step Aまとめ

ここまでで「日別サマリー」を作れるようになりました。しかし実務ではこのクエリを**管理・自動化**する必要があります。次のStep B〜Eでは、管理・自動化しようとしたときに直面する「5つの壁」を体験します。

---

### Step B：CTE体験 -「SQLが長くなる問題」（8分）【デモ+解説】

**目的**：CTEで複雑なクエリを整理する → 長くなると管理できない壁を認識

#### 複数CTEによる段階的な構築

```sql
WITH daily_events AS (
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP)
),

daily_purchases AS (
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS PURCHASE_COUNT
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    WHERE EVENT_TYPE = 'purchase'
    GROUP BY DATE(EVENT_TIMESTAMP)
)

SELECT
    E.EVENT_DATE,
    E.EVENT_COUNT,
    E.UNIQUE_USERS,
    COALESCE(P.PURCHASE_COUNT, 0) AS PURCHASE_COUNT,
    ROUND(COALESCE(P.PURCHASE_COUNT, 0)::FLOAT / E.EVENT_COUNT, 4) AS PURCHASE_RATE
FROM daily_events E
LEFT JOIN daily_purchases P ON E.EVENT_DATE = P.EVENT_DATE
ORDER BY E.EVENT_DATE DESC;
```

**CTEのメリット**：
- 各ステップを個別に確認できる（デバッグが楽）
- サブクエリのネストより可読性が高い

#### 壁1：CTE長大化

実務ではCTEが3段、4段、5段...と増えていきます。

| 問題 | 具体例 |
|------|--------|
| 1つのSQLファイルが数百行に | 可読性の低下 |
| CTEを別クエリで再利用できない | コピペが増える |
| ファイル分割ができない | `daily_events`だけ別ファイルにしたい |

→ **dbtでは各CTEを独立したSQLファイル（モデル）に分割し、`ref()`で参照できます。**

---

### Step C：VIEW体験 -「手動管理の問題」（7分）【デモ+解説】

**目的**：VIEWで再利用可能にする → 管理が大変、テストが手動という壁を認識

#### VIEW作成と利用

```sql
CREATE OR REPLACE VIEW DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS AS
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP);

-- VIEWをテーブルのように使える
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS
WHERE EVENT_DATE >= DATEADD(DAY, -7, CURRENT_DATE())
ORDER BY EVENT_DATE DESC;
```

**VIEWとは**：SQLクエリに名前を付けて保存した仮想テーブル

#### 壁2：変更の影響範囲がわからない

VIEWが増えると依存関係が不透明に：
```
V_DAILY_EVENTS → RAW_EVENTS参照
V_COUNTRY_SUMMARY → RAW_EVENTS + USERS参照
V_WEEKLY_REPORT → V_DAILY_EVENTSを参照（VIEWの上にVIEW）
V_EXECUTIVE_DASHBOARD → V_WEEKLY_REPORT + V_COUNTRY_SUMMARYを参照
```
→ RAW_EVENTSのカラム名を変更したら、どのVIEWが壊れるか不明

→ **dbtでは「Lineage（データの系譜）」で依存関係を自動可視化できます。**

#### 壁3：テストが手動

```sql
-- VIEWの結果を確認するには、毎回手動でSELECT
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- NULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 範囲チェック
```

→ 面倒なのでやらなくなる → データ品質の低下

→ **dbtでは`schema.yml`にテストを定義し、`dbt test` 1コマンドで全テスト自動実行。**

---

### Step D：SP体験 -「テスト困難の問題」（8分）【デモ+解説】

**目的**：SPで複数ステップをまとめる → テスト困難・Git管理困難の壁を認識

#### シンプルなストアドプロシジャ

```sql
CREATE OR REPLACE PROCEDURE DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY()
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
BEGIN
    DELETE FROM DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY;

    INSERT INTO DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY (
        EVENT_DATE, EVENT_COUNT, UNIQUE_USERS, UNIQUE_SESSIONS
    )
    SELECT
        DATE(EVENT_TIMESTAMP), COUNT(*),
        COUNT(DISTINCT USER_ID), COUNT(DISTINCT SESSION_ID)
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP);

    RETURN 'Daily summary completed';
END;
$$;

CALL DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY();
```

**SPとは**：複数のSQLを順番に実行する「プログラム」

#### 壁4：テスト困難 / Git管理困難

| 問題 | 説明 |
|------|------|
| **テスト困難** | DELETE + INSERTが走る → 「ステップ2だけテスト」ができない |
| **デバッグ困難** | 中間結果が見えない。エラー時、前のステップは実行済み |
| **Git管理困難** | CREATE PROCEDURE文の中にSQLが埋め込まれている → 差分が見づらい |
| **再利用困難** | ロジックの一部を別SPで使いたい → コピペが増える |

→ **dbtでは各ステップが独立したSQLファイル → 個別テスト、Git差分明確、再利用可能。**

---

### Step E：Task体験 -「依存管理の問題」（5分）【デモ+解説】

**目的**：Taskで定期実行する → 依存管理が手動で破綻する壁を認識

#### タスク間の依存関係（AFTER句）

```sql
-- 親タスク：毎日1時に日別集計
CREATE OR REPLACE TASK TSK_PARENT_DAILY
WAREHOUSE = COMPUTE_WH
SCHEDULE = 'USING CRON 0 1 * * * UTC'
AS
CALL SP_CALCULATE_DAILY_SUMMARY();

-- 子タスク：親の完了後に週別集計
CREATE OR REPLACE TASK TSK_CHILD_WEEKLY
WAREHOUSE = COMPUTE_WH
AFTER TSK_PARENT_DAILY
AS
INSERT INTO WEEKLY_SUMMARY (WEEK_START, WEEK_END, EVENT_COUNT, UNIQUE_USERS)
SELECT
    DATE_TRUNC('WEEK', EVENT_DATE), DATEADD(DAY, 6, DATE_TRUNC('WEEK', EVENT_DATE)),
    SUM(EVENT_COUNT), SUM(UNIQUE_USERS)
FROM DAILY_SUMMARY
GROUP BY DATE_TRUNC('WEEK', EVENT_DATE);
```

**AFTER句**：子タスクは親タスク完了後に自動実行される

#### 壁5：DAGが手動管理で破綻

```
実務でタスクが増えると：
  TSK_CLEAN_EVENTS
   ├─ TSK_DAILY_SUMMARY
   │   ├─ TSK_WEEKLY_SUMMARY
   │   └─ TSK_MONTHLY_KPI
   ├─ TSK_ACTIVE_USERS
   │   └─ TSK_CHURN_ANALYSIS
   └─ TSK_SESSION_SUMMARY
       └─ TSK_FUNNEL_REPORT
```

→ AFTER句の指定ミスで実行順序が壊れる。全体像が見えない。

→ **dbtでは`ref()`を書くだけでDAGを自動生成 → 正しい順序で自動実行。**

---

### SQL 1コマ目まとめ -「SQLの5つの壁」（5分）

Step A〜Eで体験した「SQLだけでは解決しにくい問題」：

| 壁 | 体験ステップ | SQL手法 | 問題 |
|----|-------------|---------|------|
| **壁1** | Step B（CTE） | CTE多段化 | ファイル分割できない → 可読性低下 |
| **壁2** | Step C（VIEW） | CREATE VIEW | 変更の影響範囲がわからない |
| **壁3** | Step C（VIEW） | 手動SELECT検証 | テストが属人化、やらなくなる |
| **壁4** | Step D（SP） | ストアドプロシジャ | テスト困難、Git管理困難 |
| **壁5** | Step E（Task） | AFTER句 | DAGが手動管理で破綻 |

**次のコマ（dbt入門）では**、これらの壁を1つずつ突破していきます。

---

## 初心者コース・2コマ目：dbt入門 -「5つの壁」を突破（45分）

### Step F：dbt on Snowflake セットアップ（8分）

**目的**：Snowflake内でdbtプロジェクトを管理・実行する環境を構築

**導入**：1コマ目で「SQLの5つの壁」を体験しました。これからdbtでそれらを1つずつ解決していきます。

#### dbt on Snowflake とは

**通常のdbt CLI**
```
ローカル → dbtインストール → dbt run → Snowflake
```

**dbt on Snowflake**
```
Snowflake内でプロジェクト管理・実行
Git統合、UI操作可能
```

#### セットアップ手順

1. **Snowflakeでのスキーマ作成**
```sql
CREATE DATABASE DIESELPJ_TEST;
CREATE SCHEMA DIESELPJ_TEST.STAGING;
CREATE SCHEMA DIESELPJ_TEST.MARTS;
```

2. **Git統合**
   - Snowflake Web UI → Projects を開く
   - Create New Project → Develop in Git を選択
   - リポジトリURLを入力し、GitHub認証を設定

3. **接続確認**
```bash
dbt deps
dbt debug
```

---

### Step G：Stagingモデル -「壁1 + 壁2」を突破（10分）

**目的**：1コマ目で書いたSQLをdbtモデル化し、CTE分割とVIEW自動管理を体験

**解決する壁**：
- 壁1（CTE長大化）→ モデル分割で各CTEが独立ファイルに
- 壁2（VIEW管理）→ `materialized='view'` で自動管理

#### 「staging層」とは

**staging = 生データをきれいにする層**。各ソーステーブルに対して1つのstagingモデルを作ります。

- RAW_EVENTS → stg_events_beginner（イベントの前処理）
- USERS → stg_users_beginner（ユーザーの前処理）

#### stg_events_beginner.sql（イベント前処理）

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    EVENT_ID,
    USER_ID,
    SESSION_ID,
    EVENT_TYPE,
    EVENT_TIMESTAMP,
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE
FROM {{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}
WHERE EVENT_ID IS NOT NULL
  AND USER_ID IS NOT NULL
```

**見慣れたSQL**：Step Aで学んだ `SELECT`, `WHERE`, `DATE()` だけです。新しいのは2つだけ：
- `{{ config(materialized='view') }}` → 1コマ目の `CREATE OR REPLACE VIEW` の代わり
- `{{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}` → テーブル名の代わり（dbtが依存関係を認識）

#### 壁2の突破：CREATE VIEW → materialized config

| 1コマ目（SQL） | dbt |
|---------------|-----|
| `CREATE OR REPLACE VIEW V_DAILY_EVENTS AS ...` | `{{ config(materialized='view') }}` |
| 手動でDDLを実行 | **`dbt run` で自動作成** |
| VIEWの依存関係が不透明 | **Lineageで自動可視化** |

#### stg_users_beginner.sql（ユーザー前処理）

同じパターンの2つ目。**staging層は各ソースに1つ**、というルールを体験します。

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    USER_ID,
    SIGNUP_DATE,
    UPPER(COUNTRY) AS COUNTRY,
    PLAN_TYPE,
    IS_ACTIVE
FROM {{ source('DIESELPJ_TEST', 'USERS') }}
```

stg_events_beginnerと同じ構造パターン。**繰り返しで定着**させます。

#### 実行

```bash
dbt run -s stg_events_beginner stg_users_beginner
```

**ポイント**：
- `{{ source() }}` でソーステーブルを参照（dbtが依存関係を認識）
- `{{ config(materialized='view') }}` でVIEWとして自動作成
- SQLは Step A で学んだ SELECT, WHERE, DATE() をそのまま活用
- 2つのモデルが同じパターン →「staging層は各ソースに1つ」が理解できる

---

### Step H：Martsモデル -「壁1 + 壁4 + 壁5」を突破（10分）

**目的**：SP代替としてのdbtモデルを体験し、`ref()` で依存関係の自動管理を学ぶ

**解決する壁**：
- 壁1（CTE長大化）→ ファイル分割で5段CTEが1段に縮小
- 壁4（SP複雑化）→ 各モデルが独立SQLファイル、DELETE+INSERT不要
- 壁5（Task依存管理）→ `ref()` でDAG自動生成

#### 「marts層」とは

**marts = ビジネスの答えを出す層**。staging層のモデルを `ref()` で組み合わせて集計します。

#### daily_summary_beginner.sql

```sql
{{ config(
    materialized='table',
    tags=['marts', 'beginner']
) }}

-- CTE：stagingモデルを結合（1コマ目では5段CTEだったが、ファイル分割で1段に）
WITH joined AS (
    SELECT
        E.EVENT_DATE,
        U.COUNTRY,
        E.EVENT_ID,
        E.USER_ID,
        E.EVENT_TYPE
    FROM {{ ref('stg_events_beginner') }} E
    INNER JOIN {{ ref('stg_users_beginner') }} U
        ON E.USER_ID = U.USER_ID
)

SELECT
    EVENT_DATE,
    COUNTRY,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
    COUNT(CASE WHEN EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM joined
GROUP BY EVENT_DATE, COUNTRY
```

**見慣れたSQL**：Step Aで学んだ `INNER JOIN`, `GROUP BY`, `COUNT`, `CASE` をそのまま使用。新しいのは `{{ ref() }}` だけです。

#### 壁1の突破：5段CTE → 1段CTE

| 1コマ目（Step B） | dbt |
|-------------------|-----|
| 1つのSQLファイルに5段CTE | **3つのファイルに分割 → CTEが1段に** |
| `WITH daily_events AS (...), performance AS (...), ...` | stg_events_beginner.sql + stg_users_beginner.sql + daily_summary_beginner.sql |
| ファイル分割できない | **各モデルを個別にテスト・修正可能** |

#### 壁4の突破：SP → dbtモデル

| 1コマ目（Step D: SP） | dbt |
|----------------------|-----|
| `DELETE FROM ... INSERT INTO ...` | `{{ config(materialized='table') }}` で自動管理 |
| 「ステップ2だけテスト」不可 | **各モデルを個別に`dbt run -s`で実行可能** |
| Git差分が見づらい | **普通のSQLファイル → diff明確** |
| ロジック再利用 → コピペ | **`ref()`で参照** |

#### ref() の重要性 → 壁5の突破

```sql
FROM {{ ref('stg_events_beginner') }} E
INNER JOIN {{ ref('stg_users_beginner') }} U
```

- `ref()` はモデル名を指定するだけで、dbtが**実行順序を自動決定**
- 1コマ目 Step E では `AFTER TSK_PARENT_DAILY` と手動で依存を指定していた
- dbtでは `ref()` を書くだけで、stg → marts の順序が自動的に保証される

#### materialized の違い

| 設定 | 動作 | 用途 |
|------|------|------|
| `materialized='view'` | VIEWとして作成 | staging層（毎回最新データ参照） |
| `materialized='table'` | テーブルとして作成 | marts層（集計結果を保存） |

#### 実行

```bash
dbt run -s daily_summary_beginner
```

dbtが自動的に stg_events_beginner → stg_users_beginner → daily_summary_beginner の順で実行します。

---

### Step I：テスト & Lineage -「壁3 + 壁5」を突破（10分）

**目的**：テスト自動化とDAG可視化を体験

**解決する壁**：
- 壁3（テスト手動）→ `dbt test` で自動化
- 壁5（Task依存管理）→ Lineage DAGで自動可視化

#### 1コマ目の手動テストを思い出す

Step C で学んだ手動テスト：
```sql
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- 手動でNULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 手動で範囲チェック
```
→ 面倒なのでやらなくなる → データ品質の低下

#### dbtでは：テスト定義（schema_beginner.yml）

```yaml
models:
  - name: stg_events_beginner
    columns:
      - name: EVENT_ID
        tests:
          - unique       # EVENT_ID が一意であることを検証
          - not_null     # EVENT_ID が NULL でないことを検証
      - name: USER_ID
        tests:
          - not_null     # USER_ID が NULL でないことを検証
      - name: EVENT_DATE
        tests:
          - not_null     # EVENT_DATE が NULL でないことを検証

  - name: stg_users_beginner
    columns:
      - name: USER_ID
        tests:
          - unique
          - not_null

  - name: daily_summary_beginner
    columns:
      - name: EVENT_DATE
        tests:
          - not_null
      - name: COUNTRY
        tests:
          - not_null
      - name: EVENT_COUNT
        tests:
          - not_null
```

YAMLファイルに `unique`（一意性）と `not_null`（NULL非許容）を書くだけ。

#### 壁3の突破：手動SELECT → dbt test

| 1コマ目（Step C: SQL） | dbt |
|----------------------|-----|
| `SELECT COUNT(*) WHERE col IS NULL` を手動実行 | `schema.yml` にテストを定義 |
| 面倒なのでやらなくなる | **`dbt test` 1コマンドで全モデルの品質チェック** |
| テスト結果の記録がない | **テスト結果が記録・追跡される** |

#### テスト実行

```bash
dbt test -s stg_events_beginner stg_users_beginner daily_summary_beginner
```

**テスト結果の見方**：
- `PASS` ：テスト成功（データ品質OK）
- `FAIL` ：テスト失敗（データに問題あり）

#### Lineage（データの系譜）確認

```bash
dbt docs generate
```

Snowflake UI で Lineage グラフを確認：

```
RAW_EVENTS → stg_events_beginner  ─┐
                               ├→ daily_summary_beginner
USERS      → stg_users_beginner   ─┘
```

これが `ref()` から**自動生成されたDAG**です。

#### 壁5の突破：AFTER句手動管理 → Lineage DAG

| 1コマ目（Step E: Task） | dbt |
|------------------------|-----|
| `AFTER TSK_PARENT_DAILY` を手動指定 | `ref()` を書くだけ → DAG自動生成 |
| 依存関係の全体像が見えない | **Lineageグラフで一目瞭然** |
| AFTER句のミスで順序が壊れる | **dbtが正しい順序を自動決定** |
| 新タスク追加時、どこに依存させるか困難 | **`ref()`を書けば自動的に正しい位置に** |

---

### 「5つの壁」解決マトリクス（7分）

#### 今日体験した壁と解決

| 壁 | SQL手法 | 問題 | dbtでの解決 |
|----|---------|------|------------|
| **壁1** CTE長大化 | CTE多段化 | ファイル分割不可 | **モデル分割 + `ref()`** |
| **壁2** VIEW管理 | CREATE VIEW | 影響範囲不明 | **Lineage自動生成** |
| **壁3** テスト手動 | SELECT検証 | 属人化・やらなくなる | **`dbt test` 自動化** |
| **壁4** SP複雑化 | SP巨大化 | テスト困難・Git管理困難 | **独立SQLファイル** |
| **壁5** Task依存 | AFTER句手動 | DAG管理破綻 | **`ref()` → 自動DAG** |

#### 今日作ったdbtモデルの全体像

```
[staging層 = 生データのクリーニング]
  stg_events_beginner.sql  ← {{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}
  stg_users_beginner.sql   ← {{ source('DIESELPJ_TEST', 'USERS') }}

[marts層 = ビジネスの答え]
  daily_summary_beginner.sql ← {{ ref('stg_events_beginner') }} + {{ ref('stg_users_beginner') }}

[テスト]
  schema_beginner.yml → dbt test で品質チェック
```

#### dbtで体験した4つの主要メリット

| dbtメリット | 体験内容 |
|------------|---------|
| **モジュール性と再利用性** | `ref()` でモデル参照、各モデルが独立SQLファイル |
| **依存関係の自動解決とDAG** | Lineageグラフで依存関係を可視化 |
| **テストとデータ品質** | `schema.yml` + `dbt test` で自動品質チェック |
| **ドキュメンテーション** | `dbt docs generate` でドキュメント自動生成 |

#### 今日は対象外だが実務で重要なメリット

| dbtメリット | 説明 |
|------------|------|
| **バージョン管理** | dbtモデル＝SQLファイル → Gitで自然に管理。セットアップ時にGit統合を設定済み |
| **Jinjaテンプレート** | マクロでSQLに動的ロジックを追加 |
| **環境管理** | dev / staging / production をprofileで切り替え（実務で活用） |
| **増分更新** | incrementalモデルで差分処理（大規模データ向け） |

---

## 実務での推奨アーキテクチャ

```
Raw Data (S3/API)
    ↓
[dbt Staging] → Snowflake RAW_EVENTS
    ↓
[dbt Intermediate] → Snowflake INTERMEDIATE
    ↓
[dbt Marts] → Snowflake MARTS
    ↓
BI ツール（Tableau, Looker等）
    ↓
ビジネスダッシュボード
```

### SQLとdbtの使い分け

#### SQLを使う場面
- データの初期確認（SELECT, WHERE, DISTINCT）
- アドホック分析
- シンプルな処理

#### dbtを使う場面（推奨）
- 定期的に実行するパイプライン
- 複数モデルの組み合わせ
- テスト・品質管理が重要
- チーム開発
- バージョン管理が必須

---

## 次のステップ（学習リソース）

1. **dbt公式ドキュメント** - https://docs.getdbt.com
2. **dbt Learn** - 無料オンラインコース
3. **dbt Slack コミュニティ** - 質問・相談の場
4. **Snowflake + dbt連携** - Snowflake dbt Integration ガイド
5. **高度なトピック** - Dynamic Tables、dbt Metrics、dbt Cloud

---

## Q&A想定集

### Q1：このコースの位置づけは？

**A**：本資料は初心者コースです。SQL基礎とdbt入門を学ぶコースで、SQL未経験の方でも受講できます。

### Q2：dbtは必須ですか？

**A**：小規模プロジェクト（<100万行/日）であれば、Snowflake Taskで十分です。
ただし以下の場合はdbt推奨：
- チーム開発
- テスト・品質管理が重要
- 複雑な変換ロジック
- 将来の拡張を見据えている

### Q4：パフォーマンスはどちらが良い？

**A**：同等です。以下に注意：
- 不要なカラムは SELECT しない（SQL, dbt両方）
- JOINの順序を最適化（dbtも Snowflake が自動最適化）
- インデックス活用（Snowflakeでは CLUSTERING キー）

### Q6：テストはどのくらい詳細に書く？

**A**：最初は基本テスト：
- 主キー： `unique`
- 必須フィールド： `not_null`
- 分類値： `accepted_values`

詳細テストは後から追加：
- データ範囲チェック（0-100%等）
- 外部キー検証
- 業務ルール検証

### Q9：他のDBMS（PostgreSQL, BigQuery等）でも使える？

**A**：はい。dbtは複数DBMS対応：
- Snowflake（推奨）
- PostgreSQL
- BigQuery
- Redshift
- Databricks

ただしSnowflake固有の機能（Dynamic Tables, Clustering等）は未対応。

---

## 補足：ベストプラクティス

### SQLベストプラクティス

1. **必要なカラムのみ SELECT**
2. **フィルタリングは早期に**（WHERE句をJOIN前に）
3. **複雑なロジックはCTEで分割**
4. **GROUP BYにない列をSELECTしない**

### dbtベストプラクティス

1. **モデル名は層を示す** - `stg_`、`fct_`、`dim_`
2. **テストは必須** - `unique`、`not_null`、`accepted_values`
3. **ドキュメント必須** - `description` を全モデル・全カラムに

---

**質問・フィードバックは随時受け付けています。**