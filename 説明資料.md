# SQL & dbt ハンズオンレクチャー 説明資料（初心者コース）

## 目次

1. [イントロダクション](#イントロダクション)
2. [初心者コース](#初心者コース)
   - [1コマ目：SQL基礎＋応用エッセンス](#初心者コース1コマ目sql基礎応用エッセンス45分)
   - [2コマ目：dbt入門 -「5つの壁」を突破](#初心者コース2コマ目dbt入門5つの壁を突破45分)
3. [Q&A想定集](#qa想定集)

---

## イントロダクション

### ハンズオンの目的

本ハンズオンでは、Webアクセスログ分析をテーマに、SQLとdbtの実践的なスキルを習得します。

### コース構成

| コース | 対象者 | 前提知識 | 学ぶこと |
|--------|--------|----------|----------|
| **初心者コース**（90分） | SQL未経験〜初心者 | なし | SQL基礎＋応用エッセンス + dbt入門 |

**初心者コースの特徴**：1コマ目でSQL基礎に加えてCTE・VIEW・SP・Taskのエッセンスを体験し、「SQLだけでは解決しにくい5つの壁」を認識します。2コマ目でdbtがそれらの壁をどう解決するかを体験します。

---

# 初心者コース

## 前提知識
- なし（SQL未経験でもOK）

## 学ぶこと
- SQLの基本操作（SELECT, JOIN, GROUP BY）
- SQLの応用技術のエッセンス（CTE, VIEW, ストアドプロシジャ, Task）
- **SQLだけでは解決しにくい「5つの壁」**の認識
- dbtの基本概念（モデル、ref、テスト、Lineage）
- dbtが「5つの壁」をどう解決するか

---

## 初心者コース・1コマ目：SQL基礎＋応用エッセンス（45分）

---

### Step A：SQL基礎ダイジェスト（12分）【ハンズオン】

**目的**：SELECT / WHERE / JOIN / GROUP BY の基本を短時間で体験

---

#### A-1. SELECT + WHERE：データの抽出とフィルタリング（3分）

**目的**：データの抽出と重複排除の基本を学びます。Snowflakeでのデータ確認の第一歩です。

![SELECT + WHERE クエリ実行フロー](./diagrams/step_a1_select_where.svg)

```sql
-- まずデータの全体像を確認
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS LIMIT 10;

-- 必要なカラムだけ取得し、条件で絞り込む
SELECT
    EVENT_ID, USER_ID, EVENT_TYPE,
    EVENT_TIMESTAMP, COUNTRY
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
WHERE EVENT_TYPE = 'purchase'
  AND COUNTRY IN ('US', 'JP')
LIMIT 20;

-- どんなイベント種別があるか確認（重複排除）
SELECT DISTINCT EVENT_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
ORDER BY EVENT_TYPE;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **SELECT** | 必要なカラムだけ指定する（`SELECT *` は避ける） |
| **WHERE** | 条件で絞る（`AND` / `IN` で複数条件） |
| **DISTINCT** | ユニーク値を確認 → データ品質チェックの第一歩 |
| **LIMIT** | 取得行数を制限（大量データの確認時に必須） |

---

#### A-2. INNER JOIN：イベントログにユーザー属性を結合（4分）

**目的**：複数のテーブルを結合してデータを統合します。実務での分析は、ほとんどの場合、複数テーブルの結合から始まります。

![INNER JOIN クエリ実行フロー](./diagrams/step_a2_inner_join.svg)

```sql
SELECT
    E.EVENT_ID, E.USER_ID,
    E.EVENT_TYPE, E.EVENT_TIMESTAMP,
    U.COUNTRY, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE E.EVENT_TYPE = 'purchase'
LIMIT 20;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **INNER JOIN** | 両テーブルに存在するレコードのみ結合 |
| **ON句** | `E.USER_ID = U.USER_ID` で結合キーを指定 |
| **エイリアス** | `E`, `U` はテーブルの短い別名 |
| **WHERE** | 結合後に `EVENT_TYPE = 'purchase'` でフィルタ |

---

#### A-3. LEFT JOIN：データ品質チェック（マッチしないレコード検出）

**目的**：LEFT JOINとIS NULLの組み合わせで、データ品質の問題を検出します。

![LEFT JOIN クエリ実行フロー](./diagrams/step_a3_left_join.svg)

```sql
SELECT
    E.EVENT_ID, E.USER_ID, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
LEFT JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE U.USER_ID IS NULL
LIMIT 20;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **LEFT JOIN** | 左テーブルの全レコード（マッチしない場合はNULL） |
| **WHERE IS NULL** | USERSに存在しないUSER_IDのイベントを検出 |
| **データ品質** | マスタデータの欠損を発見するテクニック |

---

#### A-4. GROUP BY + 集計関数：データの集約（4分）

**目的**：大量のデータを集計して、意味のあるメトリクスに変換します。データ分析の中核です。

![GROUP BY クエリ実行フロー](./diagrams/step_a4_group_by.svg)

```sql
-- 日別のイベント数を集計
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP)
ORDER BY EVENT_DATE DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **GROUP BY** | 同じ値を持つ行をグループ化して集計 |
| **COUNT(*)** | 全行数をカウント |
| **COUNT(DISTINCT ...)** | ユニーク値の数をカウント |
| **DATE()** | タイムスタンプから日付だけ抽出 |
| **ORDER BY** | 結果を並び替え（DESCで降順） |

---

#### A-5. CASE + GROUP BY：条件付き集計（ファネル分析の基礎）

**目的**：CASE文で条件ごとに集計し、ファネル分析の基礎を学びます。

![CASE + GROUP BY クエリ実行フロー](./diagrams/step_a5_case_aggregation.svg)

```sql
SELECT
    U.COUNTRY,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(CASE WHEN E.EVENT_TYPE = 'page_view' THEN 1 END) AS PAGEVIEW_COUNT,
    COUNT(CASE WHEN E.EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
GROUP BY U.COUNTRY
ORDER BY TOTAL_EVENTS DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **CASE文** | 条件に応じて値を返す（IF文のようなもの） |
| **条件付き集計** | イベント種別ごとの件数を横持ちで計算 |
| **ファネル分析** | page_view → purchase の変換率を確認する基礎 |

---

#### A-6. HAVING：集計後のフィルタリング

**目的**：集計結果に対してフィルタリングを行います。WHEREとの違いを理解します。

![HAVING クエリ実行フロー](./diagrams/step_a6_having.svg)

```sql
SELECT
    USER_ID,
    COUNT(*) AS EVENT_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY USER_ID
HAVING COUNT(*) > 100
ORDER BY EVENT_COUNT DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **HAVING** | GROUP BY**の後**に集計結果をフィルタ |
| **WHERE** | GROUP BY**の前**に個別行をフィルタ |
| **使い分け** | 個別行の絞り込み → WHERE、集計結果の絞り込み → HAVING |

---

#### Step Aまとめ

ここまでで「日別サマリー」を作れるようになりました。しかし実務ではこのクエリを**管理・自動化**する必要があります。次のStep B〜Eでは、管理・自動化しようとしたときに直面する「5つの壁」を体験します。

---

### Step B：CTE体験 -「SQLが長くなる問題」（8分）【デモ+解説】

**目的**：CTEで複雑なクエリを整理する → 長くなると管理できない壁を認識

---

#### B-1. CTE基礎：1つのCTEで中間結果を作る

**目的**：WITH句で「名前付きの中間テーブル」を定義し、クエリを段階的に構築します。

![CTE基礎 クエリ実行フロー](./diagrams/step_b1_single_cte.svg)

```sql
WITH daily_events AS (
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP)
)
SELECT *
FROM daily_events
WHERE EVENT_DATE >= DATEADD(DAY, -7, CURRENT_DATE())
ORDER BY EVENT_DATE DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **WITH句（CTE）** | クエリの中に「名前付きの中間テーブル」を定義 |
| **daily_events** | CTEの名前（後のSELECTで参照できる） |
| **段階的構築** | 複雑なロジックを分けて組み立てられる |

---

#### B-2. 複数CTE：段階的にロジックを構築する

**目的**：複数のCTEを組み合わせて、段階的にデータを加工します。

![複数CTE クエリ実行フロー](./diagrams/step_b2_multi_cte.svg)

```sql
WITH daily_events AS (
    -- ステップ1：日別の全イベント集計
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP)
),

daily_purchases AS (
    -- ステップ2：日別の購入イベント集計
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS PURCHASE_COUNT,
        COUNT(DISTINCT USER_ID) AS PURCHASING_USERS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    WHERE EVENT_TYPE = 'purchase'
    GROUP BY DATE(EVENT_TIMESTAMP)
)

-- ステップ3：結合して購入率を計算
SELECT
    E.EVENT_DATE,
    E.EVENT_COUNT,
    E.UNIQUE_USERS,
    COALESCE(P.PURCHASE_COUNT, 0) AS PURCHASE_COUNT,
    ROUND(COALESCE(P.PURCHASE_COUNT, 0)::FLOAT / E.EVENT_COUNT, 4) AS PURCHASE_RATE
FROM daily_events E
LEFT JOIN daily_purchases P
    ON E.EVENT_DATE = P.EVENT_DATE
ORDER BY E.EVENT_DATE DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **複数CTE** | カンマ区切りで複数定義し、段階的に構築 |
| **デバッグが楽** | 各CTEを個別にSELECTして中間結果を確認できる |
| **LEFT JOIN** | 購入がない日も含めて結合（COALESCE で0に変換） |

---

#### B-3. 実務規模のCTE：3段階で複雑化 → 壁1：CTE長大化

**目的**：実務では3段、4段、5段とCTEが増えていく問題を認識します。

![実務規模CTE クエリ実行フロー](./diagrams/step_b3_complex_cte.svg)

```sql
WITH daily_performance AS (
    -- ステップ1：基本集計
    SELECT
        DATE(E.EVENT_TIMESTAMP) AS EVENT_DATE,
        U.COUNTRY, U.PLAN_TYPE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT E.USER_ID) AS USER_COUNT,
        COUNT(DISTINCT CASE WHEN E.EVENT_TYPE = 'purchase' THEN E.EVENT_ID END) AS PURCHASE_COUNT
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
    INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
    WHERE E.EVENT_TIMESTAMP >= DATEADD(DAY, -30, CURRENT_DATE())
    GROUP BY DATE(E.EVENT_TIMESTAMP), U.COUNTRY, U.PLAN_TYPE
),

performance_with_metrics AS (
    -- ステップ2：メトリクス計算
    SELECT
        EVENT_DATE, COUNTRY, PLAN_TYPE,
        EVENT_COUNT, USER_COUNT, PURCHASE_COUNT,
        ROUND(EVENT_COUNT::FLOAT / USER_COUNT, 2) AS EVENTS_PER_USER,
        ROUND(PURCHASE_COUNT::FLOAT / USER_COUNT, 4) AS PURCHASE_RATE,
        CASE
            WHEN ROUND(PURCHASE_COUNT::FLOAT / USER_COUNT, 4) >= 0.05 THEN 'High'
            WHEN ROUND(PURCHASE_COUNT::FLOAT / USER_COUNT, 4) >= 0.02 THEN 'Medium'
            ELSE 'Low'
        END AS CONVERSION_TIER
    FROM daily_performance
)

-- ステップ3：最終出力
SELECT *
FROM performance_with_metrics
ORDER BY EVENT_DATE DESC, PURCHASE_RATE DESC;
```

#### 壁1：CTE長大化

| 問題 | 具体例 |
|------|--------|
| 1つのSQLファイルが数百行に | 可読性の低下 |
| CTEを別クエリで再利用できない | コピペが増える |
| ファイル分割ができない | `daily_performance` だけ別ファイルにしたい |

→ **dbtでは各CTEを独立したSQLファイル（モデル）に分割し、`ref()` で参照できます。**

---

### Step C：VIEW体験 -「手動管理の問題」（7分）【デモ+解説】

**目的**：VIEWで再利用可能にする → 管理が大変、テストが手動という壁を認識

---

#### C-1. VIEW作成：よく使うクエリを保存する

**目的**：よく使うクエリを再利用可能な「仮想テーブル」として保存します。

![VIEW作成 実行フロー](./diagrams/step_c1_create_view.svg)

```sql
CREATE OR REPLACE VIEW DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS AS
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
    COUNT(DISTINCT SESSION_ID) AS UNIQUE_SESSIONS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP);

-- VIEWを普通のテーブルのように使える
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS
WHERE EVENT_DATE >= DATEADD(DAY, -7, CURRENT_DATE())
ORDER BY EVENT_DATE DESC;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **VIEW** | SQLクエリに名前を付けて保存した仮想テーブル |
| **データは保持しない** | 参照するたびにクエリが再実行される |
| **再利用性** | 複数のアナリストが同じロジックを共有できる |

---

#### C-2. VIEW内でのJOIN + 壁2 & 壁3

**目的**：JOINを含む複雑なVIEWを作成し、管理・テストの課題を認識します。

![VIEW + JOIN 実行フロー](./diagrams/step_c2_view_join.svg)

```sql
CREATE OR REPLACE VIEW DIESELPJ_TEST.DBT_HANDSON.V_COUNTRY_DAILY_SUMMARY AS
SELECT
    DATE(E.EVENT_TIMESTAMP) AS EVENT_DATE,
    U.COUNTRY,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT E.USER_ID) AS USER_COUNT,
    COUNT(DISTINCT CASE WHEN E.EVENT_TYPE = 'purchase' THEN E.EVENT_ID END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
GROUP BY DATE(E.EVENT_TIMESTAMP), U.COUNTRY;

-- 使用例
SELECT
    EVENT_DATE, COUNTRY, EVENT_COUNT, PURCHASE_COUNT,
    ROUND(PURCHASE_COUNT::FLOAT / USER_COUNT, 4) AS PURCHASE_RATE
FROM DIESELPJ_TEST.DBT_HANDSON.V_COUNTRY_DAILY_SUMMARY
WHERE EVENT_DATE >= DATEADD(DAY, -7, CURRENT_DATE())
ORDER BY EVENT_DATE DESC, PURCHASE_COUNT DESC;
```

#### 壁2：変更の影響範囲がわからない

VIEWが増えると依存関係が不透明に：
```
V_DAILY_EVENTS        → RAW_EVENTS参照
V_COUNTRY_SUMMARY     → RAW_EVENTS + USERS参照
V_WEEKLY_REPORT       → V_DAILY_EVENTSを参照（VIEWの上にVIEW）
V_EXECUTIVE_DASHBOARD → V_WEEKLY_REPORT + V_COUNTRY_SUMMARYを参照
```
→ RAW_EVENTSのカラム名を変更したら、どのVIEWが壊れるか不明

→ **dbtでは「Lineage（データの系譜）」で依存関係を自動可視化できます。**

#### 壁3：テストが手動

```sql
-- VIEWの結果を確認するには、毎回手動でSELECT
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- NULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 範囲チェック
```

→ 面倒なのでやらなくなる → データ品質の低下

→ **dbtでは `schema.yml` にテストを定義し、`dbt test` 1コマンドで全テスト自動実行。**

---

### Step D：SP体験 -「テスト困難の問題」（8分）【デモ+解説】

**目的**：SPで複数ステップをまとめる → テスト困難・Git管理困難の壁を認識

---

#### D-1. ストアドプロシジャ：複数ステップの処理をまとめる

**目的**：複数ステップの処理をまとめ、定期実行パイプラインの基礎を構築します。

![ストアドプロシジャ 実行フロー](./diagrams/step_d1_stored_procedure.svg)

```sql
-- 前提：SPが更新するテーブルを先に作成
CREATE OR REPLACE TABLE DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY (
    EVENT_DATE DATE,
    EVENT_COUNT INTEGER,
    UNIQUE_USERS INTEGER,
    UNIQUE_SESSIONS INTEGER,
    CREATED_AT TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
);

-- ストアドプロシジャ作成
CREATE OR REPLACE PROCEDURE DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY()
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
BEGIN
    -- ステップ1：既存データをクリア
    DELETE FROM DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY;

    -- ステップ2：日別集計を挿入
    INSERT INTO DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY (
        EVENT_DATE, EVENT_COUNT, UNIQUE_USERS, UNIQUE_SESSIONS
    )
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
        COUNT(DISTINCT SESSION_ID) AS UNIQUE_SESSIONS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP);

    RETURN 'Daily summary completed';
END;
$$;

-- 実行
CALL DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY();

-- 結果確認
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY
ORDER BY EVENT_DATE DESC
LIMIT 10;
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **SP** | 複数のSQLを順番に実行する「プログラム」 |
| **DELETE + INSERT** | 既存データをクリアしてから再計算 |
| **CALL** | SPを実行するコマンド |

#### 壁4：テスト困難 / Git管理困難

| 問題 | 説明 |
|------|------|
| **テスト困難** | DELETE + INSERTが走る → 「ステップ2だけテスト」ができない |
| **デバッグ困難** | 中間結果が見えない。エラー時、前のステップは実行済み |
| **Git管理困難** | CREATE PROCEDURE文の中にSQLが埋め込まれている → 差分が見づらい |
| **再利用困難** | ロジックの一部を別SPで使いたい → コピペが増える |

→ **dbtでは各ステップが独立したSQLファイル → 個別テスト、Git差分明確、再利用可能。**

---

### Step E：Task体験 -「依存管理の問題」（5分）【デモ+解説】

**目的**：Taskで定期実行する → 依存管理が手動で破綻する壁を認識

---

#### E-1. Task：定期実行と依存管理

**目的**：ストアドプロシジャやSQLを定期的に自動実行し、依存関係を管理します。

![Task依存管理 実行フロー](./diagrams/step_e1_task_dependency.svg)

```sql
-- 親タスク：毎日1時に日別集計を実行
CREATE OR REPLACE TASK DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY
WAREHOUSE = COMPUTE_WH
SCHEDULE = 'USING CRON 0 1 * * * UTC'
AS
CALL DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY();

-- 子タスク：親が完了してから週別集計を実行
CREATE OR REPLACE TASK DIESELPJ_TEST.DBT_HANDSON.TSK_CHILD_WEEKLY
WAREHOUSE = COMPUTE_WH
AFTER DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY
AS
INSERT INTO DIESELPJ_TEST.DBT_HANDSON.WEEKLY_SUMMARY
    (WEEK_START, WEEK_END, EVENT_COUNT, UNIQUE_USERS)
SELECT
    DATE_TRUNC('WEEK', EVENT_DATE) AS WEEK_START,
    DATEADD(DAY, 6, DATE_TRUNC('WEEK', EVENT_DATE)) AS WEEK_END,
    SUM(EVENT_COUNT) AS EVENT_COUNT,
    SUM(UNIQUE_USERS) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY
GROUP BY DATE_TRUNC('WEEK', EVENT_DATE);
```

**ポイント**：

| 要素 | 説明 |
|------|------|
| **Task** | SQLやSPを定期的に自動実行する仕組み |
| **CRON式** | `0 1 * * *` = 毎日01:00 UTCに実行 |
| **AFTER句** | 親タスク完了後に子タスクを自動実行 |
| **RESUME/SUSPEND** | タスクの有効化・停止を管理 |

**タスク管理の操作**：

```sql
-- 有効化（子 → 親の順）
ALTER TASK DIESELPJ_TEST.DBT_HANDSON.TSK_CHILD_WEEKLY RESUME;
ALTER TASK DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY RESUME;

-- 停止（親 → 子の順）
ALTER TASK DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY SUSPEND;
ALTER TASK DIESELPJ_TEST.DBT_HANDSON.TSK_CHILD_WEEKLY SUSPEND;

-- 手動実行（テスト用）
EXECUTE TASK DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY;

-- 実行履歴確認
SELECT NAME, STATE, SCHEDULED_TIME, COMPLETED_TIME, ERROR_MESSAGE
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(
    TASK_NAME => 'DIESELPJ_TEST.DBT_HANDSON.TSK_PARENT_DAILY',
    SCHEDULED_TIME_RANGE_START => DATEADD(DAY, -7, CURRENT_TIMESTAMP())
))
ORDER BY SCHEDULED_TIME DESC
LIMIT 10;
```

#### 壁5：DAGが手動管理で破綻

```
実務でタスクが増えると：
  TSK_CLEAN_EVENTS
   ├─ TSK_DAILY_SUMMARY
   │   ├─ TSK_WEEKLY_SUMMARY
   │   └─ TSK_MONTHLY_KPI
   ├─ TSK_ACTIVE_USERS
   │   └─ TSK_CHURN_ANALYSIS
   └─ TSK_SESSION_SUMMARY
       └─ TSK_FUNNEL_REPORT
```

→ AFTER句の指定ミスで実行順序が壊れる。全体像が見えない。

→ **dbtでは `ref()` を書くだけでDAGを自動生成 → 正しい順序で自動実行。**

---

### SQL 1コマ目まとめ -「SQLの5つの壁」（5分）

Step A〜Eで体験した「SQLだけでは解決しにくい問題」：

| 壁 | 体験ステップ | SQL手法 | 問題 |
|----|-------------|---------|------|
| **壁1** | Step B（CTE） | CTE多段化 | ファイル分割できない → 可読性低下 |
| **壁2** | Step C（VIEW） | CREATE VIEW | 変更の影響範囲がわからない |
| **壁3** | Step C（VIEW） | 手動SELECT検証 | テストが属人化、やらなくなる |
| **壁4** | Step D（SP） | ストアドプロシジャ | テスト困難、Git管理困難 |
| **壁5** | Step E（Task） | AFTER句 | DAGが手動管理で破綻 |

**次のコマ（dbt入門）では**、これらの壁を1つずつ突破していきます。

---

## 初心者コース・2コマ目：dbt入門 -「5つの壁」を突破（45分）

### Step F：dbt on Snowflake セットアップ（8分）

**目的**：Snowflake内でdbtプロジェクトを管理・実行する環境を構築

**導入**：1コマ目で「SQLの5つの壁」を体験しました。これからdbtでそれらを1つずつ解決していきます。

#### dbt on Snowflake とは

**通常のdbt CLI**
```
ローカル → dbtインストール → dbt run → Snowflake
```

**dbt on Snowflake**
```
Snowflake内でプロジェクト管理・実行
Git統合、UI操作可能
```

#### セットアップ手順

1. **Snowflakeでのスキーマ作成**
```sql
CREATE DATABASE DIESELPJ_TEST;
CREATE SCHEMA DIESELPJ_TEST.STAGING;
CREATE SCHEMA DIESELPJ_TEST.MARTS;
```

2. **Git統合**
   - Snowflake Web UI → Projects を開く
   - Create New Project → Develop in Git を選択
   - リポジトリURLを入力し、GitHub認証を設定

3. **接続確認**
```bash
dbt deps
dbt debug
```

---

### Step G：Stagingモデル -「壁1 + 壁2」を突破（10分）

**目的**：1コマ目で書いたSQLをdbtモデル化し、CTE分割とVIEW自動管理を体験

**解決する壁**：
- 壁1（CTE長大化）→ モデル分割で各CTEが独立ファイルに
- 壁2（VIEW管理）→ `materialized='view'` で自動管理

#### 「staging層」とは

**staging = 生データをきれいにする層**。各ソーステーブルに対して1つのstagingモデルを作ります。

- RAW_EVENTS → stg_events_beginner（イベントの前処理）
- USERS → stg_users_beginner（ユーザーの前処理）

#### stg_events_beginner.sql（イベント前処理）

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    EVENT_ID,
    USER_ID,
    SESSION_ID,
    EVENT_TYPE,
    EVENT_TIMESTAMP,
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE
FROM {{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}
WHERE EVENT_ID IS NOT NULL
  AND USER_ID IS NOT NULL
```

**見慣れたSQL**：Step Aで学んだ `SELECT`, `WHERE`, `DATE()` だけです。新しいのは2つだけ：
- `{{ config(materialized='view') }}` → 1コマ目の `CREATE OR REPLACE VIEW` の代わり
- `{{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}` → テーブル名の代わり（dbtが依存関係を認識）

#### 壁2の突破：CREATE VIEW → materialized config

| 1コマ目（SQL） | dbt |
|---------------|-----|
| `CREATE OR REPLACE VIEW V_DAILY_EVENTS AS ...` | `{{ config(materialized='view') }}` |
| 手動でDDLを実行 | **`dbt run` で自動作成** |
| VIEWの依存関係が不透明 | **Lineageで自動可視化** |

#### stg_users_beginner.sql（ユーザー前処理）

同じパターンの2つ目。**staging層は各ソースに1つ**、というルールを体験します。

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    USER_ID,
    SIGNUP_DATE,
    UPPER(COUNTRY) AS COUNTRY,
    PLAN_TYPE,
    IS_ACTIVE
FROM {{ source('DIESELPJ_TEST', 'USERS') }}
```

#### 実行

```bash
dbt run -s stg_events_beginner stg_users_beginner
```

**ポイント**：
- `{{ source() }}` でソーステーブルを参照（dbtが依存関係を認識）
- `{{ config(materialized='view') }}` でVIEWとして自動作成
- SQLは Step A で学んだ SELECT, WHERE, DATE() をそのまま活用
- 2つのモデルが同じパターン →「staging層は各ソースに1つ」が理解できる

---

### Step H：Martsモデル -「壁1 + 壁4 + 壁5」を突破（10分）

**目的**：SP代替としてのdbtモデルを体験し、`ref()` で依存関係の自動管理を学ぶ

**解決する壁**：
- 壁1（CTE長大化）→ ファイル分割で5段CTEが1段に縮小
- 壁4（SP複雑化）→ 各モデルが独立SQLファイル、DELETE+INSERT不要
- 壁5（Task依存管理）→ `ref()` でDAG自動生成

#### 「marts層」とは

**marts = ビジネスの答えを出す層**。staging層のモデルを `ref()` で組み合わせて集計します。

#### daily_summary_beginner.sql

```sql
{{ config(
    materialized='table',
    tags=['marts', 'beginner']
) }}

-- CTE：stagingモデルを結合（1コマ目では5段CTEだったが、ファイル分割で1段に）
WITH joined AS (
    SELECT
        E.EVENT_DATE,
        U.COUNTRY,
        E.EVENT_ID,
        E.USER_ID,
        E.EVENT_TYPE
    FROM {{ ref('stg_events_beginner') }} E
    INNER JOIN {{ ref('stg_users_beginner') }} U
        ON E.USER_ID = U.USER_ID
)

SELECT
    EVENT_DATE,
    COUNTRY,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
    COUNT(CASE WHEN EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM joined
GROUP BY EVENT_DATE, COUNTRY
```

**見慣れたSQL**：Step Aで学んだ `INNER JOIN`, `GROUP BY`, `COUNT`, `CASE` をそのまま使用。新しいのは `{{ ref() }}` だけです。

#### 壁1の突破：5段CTE → 1段CTE

| 1コマ目（Step B） | dbt |
|-------------------|-----|
| 1つのSQLファイルに5段CTE | **3つのファイルに分割 → CTEが1段に** |
| `WITH daily_events AS (...), performance AS (...), ...` | stg_events_beginner.sql + stg_users_beginner.sql + daily_summary_beginner.sql |
| ファイル分割できない | **各モデルを個別にテスト・修正可能** |

#### 壁4の突破：SP → dbtモデル

| 1コマ目（Step D: SP） | dbt |
|----------------------|-----|
| `DELETE FROM ... INSERT INTO ...` | `{{ config(materialized='table') }}` で自動管理 |
| 「ステップ2だけテスト」不可 | **各モデルを個別に `dbt run -s` で実行可能** |
| Git差分が見づらい | **普通のSQLファイル → diff明確** |
| ロジック再利用 → コピペ | **`ref()` で参照** |

#### ref() の重要性 → 壁5の突破

```sql
FROM {{ ref('stg_events_beginner') }} E
INNER JOIN {{ ref('stg_users_beginner') }} U
```

- `ref()` はモデル名を指定するだけで、dbtが**実行順序を自動決定**
- 1コマ目 Step E では `AFTER TSK_PARENT_DAILY` と手動で依存を指定していた
- dbtでは `ref()` を書くだけで、stg → marts の順序が自動的に保証される

#### materialized の違い

| 設定 | 動作 | 用途 |
|------|------|------|
| `materialized='view'` | VIEWとして作成 | staging層（毎回最新データ参照） |
| `materialized='table'` | テーブルとして作成 | marts層（集計結果を保存） |

#### 実行

```bash
dbt run -s daily_summary_beginner
```

dbtが自動的に stg_events_beginner → stg_users_beginner → daily_summary_beginner の順で実行します。

---

### Step I：テスト & Lineage -「壁3 + 壁5」を突破（10分）

**目的**：テスト自動化とDAG可視化を体験

**解決する壁**：
- 壁3（テスト手動）→ `dbt test` で自動化
- 壁5（Task依存管理）→ Lineage DAGで自動可視化

#### 1コマ目の手動テストを思い出す

Step C で学んだ手動テスト：
```sql
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- 手動でNULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 手動で範囲チェック
```
→ 面倒なのでやらなくなる → データ品質の低下

#### dbtでは：テスト定義（schema_beginner.yml）

```yaml
models:
  - name: stg_events_beginner
    columns:
      - name: EVENT_ID
        tests:
          - unique       # EVENT_ID が一意であることを検証
          - not_null     # EVENT_ID が NULL でないことを検証
      - name: USER_ID
        tests:
          - not_null     # USER_ID が NULL でないことを検証
      - name: EVENT_DATE
        tests:
          - not_null     # EVENT_DATE が NULL でないことを検証

  - name: stg_users_beginner
    columns:
      - name: USER_ID
        tests:
          - unique
          - not_null

  - name: daily_summary_beginner
    columns:
      - name: EVENT_DATE
        tests:
          - not_null
      - name: COUNTRY
        tests:
          - not_null
      - name: EVENT_COUNT
        tests:
          - not_null
```

YAMLファイルに `unique`（一意性）と `not_null`（NULL非許容）を書くだけ。

#### 壁3の突破：手動SELECT → dbt test

| 1コマ目（Step C: SQL） | dbt |
|----------------------|-----|
| `SELECT COUNT(*) WHERE col IS NULL` を手動実行 | `schema.yml` にテストを定義 |
| 面倒なのでやらなくなる | **`dbt test` 1コマンドで全モデルの品質チェック** |
| テスト結果の記録がない | **テスト結果が記録・追跡される** |

#### テスト実行

```bash
dbt test -s stg_events_beginner stg_users_beginner daily_summary_beginner
```

**テスト結果の見方**：
- `PASS` ：テスト成功（データ品質OK）
- `FAIL` ：テスト失敗（データに問題あり）

#### Lineage（データの系譜）確認

```bash
dbt docs generate
```

Snowflake UI で Lineage グラフを確認：

```
RAW_EVENTS → stg_events_beginner  ─┐
                               ├→ daily_summary_beginner
USERS      → stg_users_beginner   ─┘
```

これが `ref()` から**自動生成されたDAG**です。

#### 壁5の突破：AFTER句手動管理 → Lineage DAG

| 1コマ目（Step E: Task） | dbt |
|------------------------|-----|
| `AFTER TSK_PARENT_DAILY` を手動指定 | `ref()` を書くだけ → DAG自動生成 |
| 依存関係の全体像が見えない | **Lineageグラフで一目瞭然** |
| AFTER句のミスで順序が壊れる | **dbtが正しい順序を自動決定** |
| 新タスク追加時、どこに依存させるか困難 | **`ref()` を書けば自動的に正しい位置に** |

---

### 「5つの壁」解決マトリクス（7分）

#### 今日体験した壁と解決

| 壁 | SQL手法 | 問題 | dbtでの解決 |
|----|---------|------|------------|
| **壁1** CTE長大化 | CTE多段化 | ファイル分割不可 | **モデル分割 + `ref()`** |
| **壁2** VIEW管理 | CREATE VIEW | 影響範囲不明 | **Lineage自動生成** |
| **壁3** テスト手動 | SELECT検証 | 属人化・やらなくなる | **`dbt test` 自動化** |
| **壁4** SP複雑化 | SP巨大化 | テスト困難・Git管理困難 | **独立SQLファイル** |
| **壁5** Task依存 | AFTER句手動 | DAG管理破綻 | **`ref()` → 自動DAG** |

#### 今日作ったdbtモデルの全体像

```
[staging層 = 生データのクリーニング]
  stg_events_beginner.sql  ← {{ source('DIESELPJ_TEST', 'RAW_EVENTS') }}
  stg_users_beginner.sql   ← {{ source('DIESELPJ_TEST', 'USERS') }}

[marts層 = ビジネスの答え]
  daily_summary_beginner.sql ← {{ ref('stg_events_beginner') }} + {{ ref('stg_users_beginner') }}

[テスト]
  schema_beginner.yml → dbt test で品質チェック
```

#### dbtで体験した4つの主要メリット

| dbtメリット | 体験内容 |
|------------|---------|
| **モジュール性と再利用性** | `ref()` でモデル参照、各モデルが独立SQLファイル |
| **依存関係の自動解決とDAG** | Lineageグラフで依存関係を可視化 |
| **テストとデータ品質** | `schema.yml` + `dbt test` で自動品質チェック |
| **ドキュメンテーション** | `dbt docs generate` でドキュメント自動生成 |

#### 今日は対象外だが実務で重要なメリット

| dbtメリット | 説明 |
|------------|------|
| **バージョン管理** | dbtモデル＝SQLファイル → Gitで自然に管理。セットアップ時にGit統合を設定済み |
| **Jinjaテンプレート** | マクロでSQLに動的ロジックを追加 |
| **環境管理** | dev / staging / production をprofileで切り替え（実務で活用） |
| **増分更新** | incrementalモデルで差分処理（大規模データ向け） |

---

## 実務での推奨アーキテクチャ

```
Raw Data (S3/API)
    ↓
[dbt Staging] → Snowflake RAW_EVENTS
    ↓
[dbt Intermediate] → Snowflake INTERMEDIATE
    ↓
[dbt Marts] → Snowflake MARTS
    ↓
BI ツール（Tableau, Looker等）
    ↓
ビジネスダッシュボード
```

### SQLとdbtの使い分け

#### SQLを使う場面
- データの初期確認（SELECT, WHERE, DISTINCT）
- アドホック分析
- シンプルな処理

#### dbtを使う場面（推奨）
- 定期的に実行するパイプライン
- 複数モデルの組み合わせ
- テスト・品質管理が重要
- チーム開発
- バージョン管理が必須

---

## 次のステップ（学習リソース）

1. **dbt公式ドキュメント** - https://docs.getdbt.com
2. **dbt Learn** - 無料オンラインコース
3. **dbt Slack コミュニティ** - 質問・相談の場
4. **Snowflake + dbt連携** - Snowflake dbt Integration ガイド
5. **高度なトピック** - Dynamic Tables、dbt Metrics、dbt Cloud

---

## Q&A想定集

### Q1：このコースの位置づけは？

**A**：本資料は初心者コースです。SQL基礎とdbt入門を学ぶコースで、SQL未経験の方でも受講できます。

### Q2：dbtは必須ですか？

**A**：小規模プロジェクト（<100万行/日）であれば、Snowflake Taskで十分です。
ただし以下の場合はdbt推奨：
- チーム開発
- テスト・品質管理が重要
- 複雑な変換ロジック
- 将来の拡張を見据えている

### Q3：パフォーマンスはどちらが良い？

**A**：同等です。以下に注意：
- 不要なカラムは SELECT しない（SQL, dbt両方）
- JOINの順序を最適化（dbtも Snowflake が自動最適化）
- インデックス活用（Snowflakeでは CLUSTERING キー）

### Q4：テストはどのくらい詳細に書く？

**A**：最初は基本テスト：
- 主キー： `unique`
- 必須フィールド： `not_null`
- 分類値： `accepted_values`

詳細テストは後から追加：
- データ範囲チェック（0-100%等）
- 外部キー検証
- 業務ルール検証

### Q5：他のDBMS（PostgreSQL, BigQuery等）でも使える？

**A**：はい。dbtは複数DBMS対応：
- Snowflake（推奨）
- PostgreSQL
- BigQuery
- Redshift
- Databricks

ただしSnowflake固有の機能（Dynamic Tables, Clustering等）は未対応。

---

## 補足：ベストプラクティス

### SQLベストプラクティス

1. **必要なカラムのみ SELECT**
2. **フィルタリングは早期に**（WHERE句をJOIN前に）
3. **複雑なロジックはCTEで分割**
4. **GROUP BYにない列をSELECTしない**

### dbtベストプラクティス

1. **モデル名は層を示す** - `stg_`、`fct_`、`dim_`
2. **テストは必須** - `unique`、`not_null`、`accepted_values`
3. **ドキュメント必須** - `description` を全モデル・全カラムに

---

**質問・フィードバックは随時受け付けています。**
