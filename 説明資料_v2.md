# SQL & dbt ハンズオンレクチャー 説明資料

## 目次

1. [イントロダクション](#イントロダクション)
2. [初心者コース](#初心者コース)
   - [1コマ目：SQL基礎＋応用エッセンス](#初心者コース1コマ目sql基礎応用エッセンス45分)
   - [2コマ目：dbt入門 -「5つの壁」を突破](#初心者コース2コマ目dbt入門5つの壁を突破45分)
3. [中級者コース](#中級者コース)
   - [1コマ目：SQL詳細マスター](#中級者コース1コマ目sql詳細マスター45分)
   - [2コマ目：dbt実践](#中級者コース2コマ目dbt実践45分)
4. [Q&A想定集](#qa想定集)

---

## イントロダクション

### ハンズオンの目的

本ハンズオンでは、Webアクセスログ分析をテーマに、SQLとdbtの実践的なスキルを習得します。

### コース構成

| コース | 対象者 | 前提知識 | 学ぶこと |
|--------|--------|----------|----------|
| **初心者コース**（90分） | SQL未経験〜初心者 | なし | SQL基礎＋応用エッセンス + dbt入門 |
| **中級者コース**（90分） | SQL基礎を習得済み | SELECT, JOIN, GROUP BY | SQL詳細マスター + dbt実践 |

各コースとも **1コマ目＝SQL、2コマ目＝dbt** の構成で、dbtの良さを実感できるように設計しています。

**初心者コースの特徴**：1コマ目でSQL基礎に加えてCTE・VIEW・SP・Taskのエッセンスを体験し、「SQLだけでは解決しにくい5つの壁」を認識します。2コマ目でdbtがそれらの壁をどう解決するかを体験します。

---

# 初心者コース

## 前提知識
- なし（SQL未経験でもOK）

## 学ぶこと
- SQLの基本操作（SELECT, JOIN, GROUP BY）
- SQLの応用技術のエッセンス（CTE, VIEW, ストアドプロシジャ, Task）
- **SQLだけでは解決しにくい「5つの壁」**の認識
- dbtの基本概念（モデル、ref、テスト、Lineage）
- dbtが「5つの壁」をどう解決するか

---

## 初心者コース・1コマ目：SQL基礎＋応用エッセンス（45分）

### Step A：SQL基礎ダイジェスト（12分）【ハンズオン】

**目的**：SELECT / WHERE / JOIN / GROUP BY の基本を短時間で体験

#### SELECT + WHERE + DISTINCT（3分）

```sql
-- データの確認
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS LIMIT 10;

-- 条件でフィルタリング
SELECT
    EVENT_ID, USER_ID, EVENT_TYPE, EVENT_TIMESTAMP, COUNTRY
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
WHERE EVENT_TYPE = 'purchase'
  AND COUNTRY IN ('US', 'JP')
LIMIT 20;

-- ユニークな値を確認
SELECT DISTINCT EVENT_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
ORDER BY EVENT_TYPE;
```

**ポイント**：
- `SELECT *` は避け、必要なカラムだけ指定
- `WHERE` で条件を絞る（AND / IN で複数条件）
- `DISTINCT` でユニーク値を確認 → データ品質チェックの第一歩

#### JOIN（4分）

```sql
-- INNER JOIN：イベントログにユーザー属性を結合
SELECT
    E.EVENT_ID, E.USER_ID, E.EVENT_TYPE, E.EVENT_TIMESTAMP,
    U.COUNTRY, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE E.EVENT_TYPE = 'purchase'
LIMIT 20;

-- LEFT JOIN：マッチしないレコードを検出（データ品質チェック）
SELECT E.EVENT_ID, E.USER_ID, U.PLAN_TYPE
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
LEFT JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
WHERE U.USER_ID IS NULL
LIMIT 20;
```

**JOIN種別**：
- `INNER JOIN`：両テーブルに存在するレコードのみ
- `LEFT JOIN`：左テーブルの全レコード（マッチしない場合はNULL）

#### GROUP BY + 集計関数（4分）

```sql
-- 日別のイベント数を集計
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP)
ORDER BY EVENT_DATE DESC;

-- CASE文で条件付き集計
SELECT
    U.COUNTRY,
    COUNT(*) AS TOTAL_EVENTS,
    COUNT(CASE WHEN E.EVENT_TYPE = 'page_view' THEN 1 END) AS PAGEVIEW_COUNT,
    COUNT(CASE WHEN E.EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
GROUP BY U.COUNTRY
ORDER BY TOTAL_EVENTS DESC;
```

**ポイント**：
- `GROUP BY` で同じ値を持つ行をグループ化して集計
- `COUNT(*)` は全行数、`COUNT(DISTINCT ...)` はユニーク数
- `CASE` 文で条件付き集計 → ファネル分析の基礎

#### Step Aまとめ

ここまでで「日別サマリー」を作れるようになりました。しかし実務ではこのクエリを**管理・自動化**する必要があります。次のStep B〜Eでは、管理・自動化しようとしたときに直面する「5つの壁」を体験します。

---

### Step B：CTE体験 -「SQLが長くなる問題」（8分）【デモ+解説】

**目的**：CTEで複雑なクエリを整理する → 長くなると管理できない壁を認識

#### 複数CTEによる段階的な構築

```sql
WITH daily_events AS (
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP)
),

daily_purchases AS (
    SELECT
        DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
        COUNT(*) AS PURCHASE_COUNT
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    WHERE EVENT_TYPE = 'purchase'
    GROUP BY DATE(EVENT_TIMESTAMP)
)

SELECT
    E.EVENT_DATE,
    E.EVENT_COUNT,
    E.UNIQUE_USERS,
    COALESCE(P.PURCHASE_COUNT, 0) AS PURCHASE_COUNT,
    ROUND(COALESCE(P.PURCHASE_COUNT, 0)::FLOAT / E.EVENT_COUNT, 4) AS PURCHASE_RATE
FROM daily_events E
LEFT JOIN daily_purchases P ON E.EVENT_DATE = P.EVENT_DATE
ORDER BY E.EVENT_DATE DESC;
```

**CTEのメリット**：
- 各ステップを個別に確認できる（デバッグが楽）
- サブクエリのネストより可読性が高い

#### 壁1：CTE長大化

実務ではCTEが3段、4段、5段...と増えていきます。

| 問題 | 具体例 |
|------|--------|
| 1つのSQLファイルが数百行に | 可読性の低下 |
| CTEを別クエリで再利用できない | コピペが増える |
| ファイル分割ができない | `daily_events`だけ別ファイルにしたい |

→ **dbtでは各CTEを独立したSQLファイル（モデル）に分割し、`ref()`で参照できます。**

---

### Step C：VIEW体験 -「手動管理の問題」（7分）【デモ+解説】

**目的**：VIEWで再利用可能にする → 管理が大変、テストが手動という壁を認識

#### VIEW作成と利用

```sql
CREATE OR REPLACE VIEW DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS AS
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP);

-- VIEWをテーブルのように使える
SELECT * FROM DIESELPJ_TEST.DBT_HANDSON.V_DAILY_EVENTS
WHERE EVENT_DATE >= DATEADD(DAY, -7, CURRENT_DATE())
ORDER BY EVENT_DATE DESC;
```

**VIEWとは**：SQLクエリに名前を付けて保存した仮想テーブル

#### 壁2：変更の影響範囲がわからない

VIEWが増えると依存関係が不透明に：
```
V_DAILY_EVENTS → RAW_EVENTS参照
V_COUNTRY_SUMMARY → RAW_EVENTS + USERS参照
V_WEEKLY_REPORT → V_DAILY_EVENTSを参照（VIEWの上にVIEW）
V_EXECUTIVE_DASHBOARD → V_WEEKLY_REPORT + V_COUNTRY_SUMMARYを参照
```
→ RAW_EVENTSのカラム名を変更したら、どのVIEWが壊れるか不明

→ **dbtでは「Lineage（データの系譜）」で依存関係を自動可視化できます。**

#### 壁3：テストが手動

```sql
-- VIEWの結果を確認するには、毎回手動でSELECT
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- NULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 範囲チェック
```

→ 面倒なのでやらなくなる → データ品質の低下

→ **dbtでは`schema.yml`にテストを定義し、`dbt test` 1コマンドで全テスト自動実行。**

---

### Step D：SP体験 -「テスト困難の問題」（8分）【デモ+解説】

**目的**：SPで複数ステップをまとめる → テスト困難・Git管理困難の壁を認識

#### シンプルなストアドプロシジャ

```sql
CREATE OR REPLACE PROCEDURE DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY()
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
BEGIN
    DELETE FROM DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY;

    INSERT INTO DIESELPJ_TEST.DBT_HANDSON.DAILY_SUMMARY (
        EVENT_DATE, EVENT_COUNT, UNIQUE_USERS, UNIQUE_SESSIONS
    )
    SELECT
        DATE(EVENT_TIMESTAMP), COUNT(*),
        COUNT(DISTINCT USER_ID), COUNT(DISTINCT SESSION_ID)
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP);

    RETURN 'Daily summary completed';
END;
$$;

CALL DIESELPJ_TEST.DBT_HANDSON.SP_CALCULATE_DAILY_SUMMARY();
```

**SPとは**：複数のSQLを順番に実行する「プログラム」

#### 壁4：テスト困難 / Git管理困難

| 問題 | 説明 |
|------|------|
| **テスト困難** | DELETE + INSERTが走る → 「ステップ2だけテスト」ができない |
| **デバッグ困難** | 中間結果が見えない。エラー時、前のステップは実行済み |
| **Git管理困難** | CREATE PROCEDURE文の中にSQLが埋め込まれている → 差分が見づらい |
| **再利用困難** | ロジックの一部を別SPで使いたい → コピペが増える |

→ **dbtでは各ステップが独立したSQLファイル → 個別テスト、Git差分明確、再利用可能。**

---

### Step E：Task体験 -「依存管理の問題」（5分）【デモ+解説】

**目的**：Taskで定期実行する → 依存管理が手動で破綻する壁を認識

#### タスク間の依存関係（AFTER句）

```sql
-- 親タスク：毎日1時に日別集計
CREATE OR REPLACE TASK TSK_PARENT_DAILY
WAREHOUSE = COMPUTE_WH
SCHEDULE = 'USING CRON 0 1 * * * UTC'
AS
CALL SP_CALCULATE_DAILY_SUMMARY();

-- 子タスク：親の完了後に週別集計
CREATE OR REPLACE TASK TSK_CHILD_WEEKLY
WAREHOUSE = COMPUTE_WH
AFTER TSK_PARENT_DAILY
AS
INSERT INTO WEEKLY_SUMMARY (WEEK_START, WEEK_END, EVENT_COUNT, UNIQUE_USERS)
SELECT
    DATE_TRUNC('WEEK', EVENT_DATE), DATEADD(DAY, 6, DATE_TRUNC('WEEK', EVENT_DATE)),
    SUM(EVENT_COUNT), SUM(UNIQUE_USERS)
FROM DAILY_SUMMARY
GROUP BY DATE_TRUNC('WEEK', EVENT_DATE);
```

**AFTER句**：子タスクは親タスク完了後に自動実行される

#### 壁5：DAGが手動管理で破綻

```
実務でタスクが増えると：
  TSK_CLEAN_EVENTS
   ├─ TSK_DAILY_SUMMARY
   │   ├─ TSK_WEEKLY_SUMMARY
   │   └─ TSK_MONTHLY_KPI
   ├─ TSK_ACTIVE_USERS
   │   └─ TSK_CHURN_ANALYSIS
   └─ TSK_SESSION_SUMMARY
       └─ TSK_FUNNEL_REPORT
```

→ AFTER句の指定ミスで実行順序が壊れる。全体像が見えない。

→ **dbtでは`ref()`を書くだけでDAGを自動生成 → 正しい順序で自動実行。**

---

### SQL 1コマ目まとめ -「SQLの5つの壁」（5分）

Step A〜Eで体験した「SQLだけでは解決しにくい問題」：

| 壁 | 体験ステップ | SQL手法 | 問題 |
|----|-------------|---------|------|
| **壁1** | Step B（CTE） | CTE多段化 | ファイル分割できない → 可読性低下 |
| **壁2** | Step C（VIEW） | CREATE VIEW | 変更の影響範囲がわからない |
| **壁3** | Step C（VIEW） | 手動SELECT検証 | テストが属人化、やらなくなる |
| **壁4** | Step D（SP） | ストアドプロシジャ | テスト困難、Git管理困難 |
| **壁5** | Step E（Task） | AFTER句 | DAGが手動管理で破綻 |

**次のコマ（dbt入門）では**、これらの壁を1つずつ突破していきます。

---

## 初心者コース・2コマ目：dbt入門 -「5つの壁」を突破（45分）

### Step F：dbt on Snowflake セットアップ（8分）

**目的**：Snowflake内でdbtプロジェクトを管理・実行する環境を構築

**導入**：1コマ目で「SQLの5つの壁」を体験しました。これからdbtでそれらを1つずつ解決していきます。

#### dbt on Snowflake とは

**通常のdbt CLI**
```
ローカル → dbtインストール → dbt run → Snowflake
```

**dbt on Snowflake**
```
Snowflake内でプロジェクト管理・実行
Git統合、UI操作可能
```

#### セットアップ手順

1. **Snowflakeでのスキーマ作成**
```sql
CREATE DATABASE analytics;
CREATE SCHEMA analytics.staging;
CREATE SCHEMA analytics.marts;
```

2. **Git統合**
   - Snowflake Web UI → Projects を開く
   - Create New Project → Develop in Git を選択
   - リポジトリURLを入力し、GitHub認証を設定

3. **接続確認**
```bash
dbt deps
dbt debug
```

---

### Step G：Stagingモデル -「壁1 + 壁2」を突破（10分）

**目的**：1コマ目で書いたSQLをdbtモデル化し、CTE分割とVIEW自動管理を体験

**解決する壁**：
- 壁1（CTE長大化）→ モデル分割で各CTEが独立ファイルに
- 壁2（VIEW管理）→ `materialized='view'` で自動管理

#### 「staging層」とは

**staging = 生データをきれいにする層**。各ソーステーブルに対して1つのstagingモデルを作ります。

- RAW_EVENTS → stg_events_v2（イベントの前処理）
- USERS → stg_users_v2（ユーザーの前処理）

#### stg_events_v2.sql（イベント前処理）

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    EVENT_ID,
    USER_ID,
    SESSION_ID,
    EVENT_TYPE,
    EVENT_TIMESTAMP,
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE
FROM {{ source('analytics', 'RAW_EVENTS') }}
WHERE EVENT_ID IS NOT NULL
  AND USER_ID IS NOT NULL
```

**見慣れたSQL**：Step Aで学んだ `SELECT`, `WHERE`, `DATE()` だけです。新しいのは2つだけ：
- `{{ config(materialized='view') }}` → 1コマ目の `CREATE OR REPLACE VIEW` の代わり
- `{{ source('analytics', 'RAW_EVENTS') }}` → テーブル名の代わり（dbtが依存関係を認識）

#### 壁2の突破：CREATE VIEW → materialized config

| 1コマ目（SQL） | dbt |
|---------------|-----|
| `CREATE OR REPLACE VIEW V_DAILY_EVENTS AS ...` | `{{ config(materialized='view') }}` |
| 手動でDDLを実行 | **`dbt run` で自動作成** |
| VIEWの依存関係が不透明 | **Lineageで自動可視化** |

#### stg_users_v2.sql（ユーザー前処理）

同じパターンの2つ目。**staging層は各ソースに1つ**、というルールを体験します。

```sql
{{ config(
    materialized='view',
    tags=['staging', 'beginner']
) }}

SELECT
    USER_ID,
    SIGNUP_DATE,
    UPPER(COUNTRY) AS COUNTRY,
    PLAN_TYPE,
    IS_ACTIVE
FROM {{ source('analytics', 'USERS') }}
```

stg_events_v2と同じ構造パターン。**繰り返しで定着**させます。

#### 実行

```bash
dbt run -s stg_events_v2 stg_users_v2
```

**ポイント**：
- `{{ source() }}` でソーステーブルを参照（dbtが依存関係を認識）
- `{{ config(materialized='view') }}` でVIEWとして自動作成
- SQLは Step A で学んだ SELECT, WHERE, DATE() をそのまま活用
- 2つのモデルが同じパターン →「staging層は各ソースに1つ」が理解できる

---

### Step H：Martsモデル -「壁1 + 壁4 + 壁5」を突破（10分）

**目的**：SP代替としてのdbtモデルを体験し、`ref()` で依存関係の自動管理を学ぶ

**解決する壁**：
- 壁1（CTE長大化）→ ファイル分割で5段CTEが1段に縮小
- 壁4（SP複雑化）→ 各モデルが独立SQLファイル、DELETE+INSERT不要
- 壁5（Task依存管理）→ `ref()` でDAG自動生成

#### 「marts層」とは

**marts = ビジネスの答えを出す層**。staging層のモデルを `ref()` で組み合わせて集計します。

#### daily_summary_v2.sql

```sql
{{ config(
    materialized='table',
    tags=['marts', 'beginner']
) }}

-- CTE：stagingモデルを結合（1コマ目では5段CTEだったが、ファイル分割で1段に）
WITH joined AS (
    SELECT
        E.EVENT_DATE,
        U.COUNTRY,
        E.EVENT_ID,
        E.USER_ID,
        E.EVENT_TYPE
    FROM {{ ref('stg_events_v2') }} E
    INNER JOIN {{ ref('stg_users_v2') }} U
        ON E.USER_ID = U.USER_ID
)

SELECT
    EVENT_DATE,
    COUNTRY,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
    COUNT(CASE WHEN EVENT_TYPE = 'purchase' THEN 1 END) AS PURCHASE_COUNT
FROM joined
GROUP BY EVENT_DATE, COUNTRY
```

**見慣れたSQL**：Step Aで学んだ `INNER JOIN`, `GROUP BY`, `COUNT`, `CASE` をそのまま使用。新しいのは `{{ ref() }}` だけです。

#### 壁1の突破：5段CTE → 1段CTE

| 1コマ目（Step B） | dbt |
|-------------------|-----|
| 1つのSQLファイルに5段CTE | **3つのファイルに分割 → CTEが1段に** |
| `WITH daily_events AS (...), performance AS (...), ...` | stg_events_v2.sql + stg_users_v2.sql + daily_summary_v2.sql |
| ファイル分割できない | **各モデルを個別にテスト・修正可能** |

#### 壁4の突破：SP → dbtモデル

| 1コマ目（Step D: SP） | dbt |
|----------------------|-----|
| `DELETE FROM ... INSERT INTO ...` | `{{ config(materialized='table') }}` で自動管理 |
| 「ステップ2だけテスト」不可 | **各モデルを個別に`dbt run -s`で実行可能** |
| Git差分が見づらい | **普通のSQLファイル → diff明確** |
| ロジック再利用 → コピペ | **`ref()`で参照** |

#### ref() の重要性 → 壁5の突破

```sql
FROM {{ ref('stg_events_v2') }} E
INNER JOIN {{ ref('stg_users_v2') }} U
```

- `ref()` はモデル名を指定するだけで、dbtが**実行順序を自動決定**
- 1コマ目 Step E では `AFTER TSK_PARENT_DAILY` と手動で依存を指定していた
- dbtでは `ref()` を書くだけで、stg → marts の順序が自動的に保証される

#### materialized の違い

| 設定 | 動作 | 用途 |
|------|------|------|
| `materialized='view'` | VIEWとして作成 | staging層（毎回最新データ参照） |
| `materialized='table'` | テーブルとして作成 | marts層（集計結果を保存） |

#### 実行

```bash
dbt run -s daily_summary_v2
```

dbtが自動的に stg_events_v2 → stg_users_v2 → daily_summary_v2 の順で実行します。

---

### Step I：テスト & Lineage -「壁3 + 壁5」を突破（10分）

**目的**：テスト自動化とDAG可視化を体験

**解決する壁**：
- 壁3（テスト手動）→ `dbt test` で自動化
- 壁5（Task依存管理）→ Lineage DAGで自動可視化

#### 1コマ目の手動テストを思い出す

Step C で学んだ手動テスト：
```sql
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_DATE IS NULL;  -- 手動でNULLチェック
SELECT COUNT(*) FROM V_DAILY_EVENTS WHERE EVENT_COUNT < 0;     -- 手動で範囲チェック
```
→ 面倒なのでやらなくなる → データ品質の低下

#### dbtでは：テスト定義（schema_beginner_v2.yml）

```yaml
models:
  - name: stg_events_v2
    columns:
      - name: EVENT_ID
        tests:
          - unique       # EVENT_ID が一意であることを検証
          - not_null     # EVENT_ID が NULL でないことを検証
      - name: USER_ID
        tests:
          - not_null     # USER_ID が NULL でないことを検証
      - name: EVENT_DATE
        tests:
          - not_null     # EVENT_DATE が NULL でないことを検証

  - name: stg_users_v2
    columns:
      - name: USER_ID
        tests:
          - unique
          - not_null

  - name: daily_summary_v2
    columns:
      - name: EVENT_DATE
        tests:
          - not_null
      - name: COUNTRY
        tests:
          - not_null
      - name: EVENT_COUNT
        tests:
          - not_null
```

YAMLファイルに `unique`（一意性）と `not_null`（NULL非許容）を書くだけ。

#### 壁3の突破：手動SELECT → dbt test

| 1コマ目（Step C: SQL） | dbt |
|----------------------|-----|
| `SELECT COUNT(*) WHERE col IS NULL` を手動実行 | `schema.yml` にテストを定義 |
| 面倒なのでやらなくなる | **`dbt test` 1コマンドで全モデルの品質チェック** |
| テスト結果の記録がない | **テスト結果が記録・追跡される** |

#### テスト実行

```bash
dbt test -s stg_events_v2 stg_users_v2 daily_summary_v2
```

**テスト結果の見方**：
- `PASS` ：テスト成功（データ品質OK）
- `FAIL` ：テスト失敗（データに問題あり）

#### Lineage（データの系譜）確認

```bash
dbt docs generate
```

Snowflake UI で Lineage グラフを確認：

```
RAW_EVENTS → stg_events_v2  ─┐
                               ├→ daily_summary_v2
USERS      → stg_users_v2   ─┘
```

これが `ref()` から**自動生成されたDAG**です。

#### 壁5の突破：AFTER句手動管理 → Lineage DAG

| 1コマ目（Step E: Task） | dbt |
|------------------------|-----|
| `AFTER TSK_PARENT_DAILY` を手動指定 | `ref()` を書くだけ → DAG自動生成 |
| 依存関係の全体像が見えない | **Lineageグラフで一目瞭然** |
| AFTER句のミスで順序が壊れる | **dbtが正しい順序を自動決定** |
| 新タスク追加時、どこに依存させるか困難 | **`ref()`を書けば自動的に正しい位置に** |

---

### 「5つの壁」解決マトリクス（7分）

#### 今日体験した壁と解決

| 壁 | SQL手法 | 問題 | dbtでの解決 |
|----|---------|------|------------|
| **壁1** CTE長大化 | CTE多段化 | ファイル分割不可 | **モデル分割 + `ref()`** |
| **壁2** VIEW管理 | CREATE VIEW | 影響範囲不明 | **Lineage自動生成** |
| **壁3** テスト手動 | SELECT検証 | 属人化・やらなくなる | **`dbt test` 自動化** |
| **壁4** SP複雑化 | SP巨大化 | テスト困難・Git管理困難 | **独立SQLファイル** |
| **壁5** Task依存 | AFTER句手動 | DAG管理破綻 | **`ref()` → 自動DAG** |

#### 今日作ったdbtモデルの全体像

```
[staging層 = 生データのクリーニング]
  stg_events_v2.sql  ← {{ source('analytics', 'RAW_EVENTS') }}
  stg_users_v2.sql   ← {{ source('analytics', 'USERS') }}

[marts層 = ビジネスの答え]
  daily_summary_v2.sql ← {{ ref('stg_events_v2') }} + {{ ref('stg_users_v2') }}

[テスト]
  schema_beginner_v2.yml → dbt test で品質チェック
```

#### dbtで体験した4つの主要メリット

| dbtメリット | 体験内容 |
|------------|---------|
| **モジュール性と再利用性** | `ref()` でモデル参照、各モデルが独立SQLファイル |
| **依存関係の自動解決とDAG** | Lineageグラフで依存関係を可視化 |
| **テストとデータ品質** | `schema.yml` + `dbt test` で自動品質チェック |
| **ドキュメンテーション** | `dbt docs generate` でドキュメント自動生成 |

#### 今日は対象外だが実務で重要なメリット

| dbtメリット | 説明 |
|------------|------|
| **バージョン管理** | dbtモデル＝SQLファイル → Gitで自然に管理。セットアップ時にGit統合を設定済み |
| **Jinjaテンプレート** | マクロでSQLに動的ロジックを追加（中級者コースで体験） |
| **環境管理** | dev / staging / production をprofileで切り替え（実務で活用） |
| **増分更新** | incrementalモデルで差分処理（大規模データ向け） |

---

# 中級者コース

## 前提知識
- SELECT, WHERE, DISTINCT が使える
- JOIN（INNER, LEFT）が書ける
- GROUP BY と集計関数が使える

## 学ぶこと
- SELECT/JOIN/GROUP BY の応用パターン
- CTE、VIEW、ストアドプロシジャ、タスクの詳細な使い方
- dbtのIntermediate層、Macros、高度テスト、ドキュメント自動生成
- SP + Task vs dbt の比較

---

## 中級者コース・1コマ目：SQL詳細マスター（45分）

### ステップ1：SELECT/JOIN/GROUP BY 応用パターン（10分）

**目的**：SQL基礎の応用テクニックを習得

#### FULL OUTER JOINとセルフジョイン

```sql
-- FULL OUTER JOIN：両テーブルの完全照合
SELECT
    E.USER_ID AS EVENT_USER_ID,
    U.USER_ID AS USER_TABLE_USER_ID,
    CASE
        WHEN E.USER_ID IS NULL THEN 'Users only'
        WHEN U.USER_ID IS NULL THEN 'Events only'
        ELSE 'Both tables'
    END AS MATCH_STATUS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
FULL OUTER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID
LIMIT 20;

-- セルフジョイン：同じテーブル同士の結合（連続イベント分析）
SELECT
    E1.USER_ID,
    E1.EVENT_TIMESTAMP AS FIRST_EVENT,
    E2.EVENT_TIMESTAMP AS SECOND_EVENT,
    DATEDIFF(SECOND, E1.EVENT_TIMESTAMP, E2.EVENT_TIMESTAMP) AS SECONDS_BETWEEN
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E1
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E2
    ON E1.USER_ID = E2.USER_ID
    AND E1.EVENT_ID < E2.EVENT_ID
WHERE E1.EVENT_TIMESTAMP >= DATEADD(DAY, -7, CURRENT_DATE())
LIMIT 20;
```

#### HAVING応用 + GROUP BY ALL

```sql
-- WHERE + JOIN + GROUP BY + HAVING の組み合わせ
SELECT
    U.COUNTRY,
    U.PLAN_TYPE,
    COUNT(DISTINCT E.USER_ID) AS USER_COUNT,
    COUNT(E.EVENT_ID) AS EVENT_COUNT,
    COUNT(DISTINCT CASE WHEN E.EVENT_TYPE = 'purchase' THEN E.EVENT_ID END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
WHERE E.EVENT_TIMESTAMP >= DATEADD(DAY, -7, CURRENT_DATE())
GROUP BY U.COUNTRY, U.PLAN_TYPE
HAVING COUNT(DISTINCT E.USER_ID) >= 10
ORDER BY EVENT_COUNT DESC;

-- GROUP BY ALL（Snowflake拡張機能）
SELECT
    DATE(E.EVENT_TIMESTAMP) AS EVENT_DATE,
    E.EVENT_TYPE,
    E.DEVICE_TYPE,
    COUNT(*) AS EVENT_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
GROUP BY ALL
ORDER BY EVENT_DATE DESC, EVENT_COUNT DESC;
```

#### ウィンドウ関数の導入

```sql
-- GROUP BYでの集計
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS DAILY_EVENTS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP)
ORDER BY EVENT_DATE;

-- ウィンドウ関数：個別行と集計値を同時に参照
SELECT DISTINCT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) OVER (PARTITION BY DATE(EVENT_TIMESTAMP)) AS DAILY_EVENTS
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
ORDER BY EVENT_DATE;
```

---

### ステップ2：CTE マスター（10分）

**目的**：RECURSIVE CTE、ファネル分析など高度なCTEパターンを習得

#### RECURSIVE CTE（日付マスタ生成）

```sql
WITH date_range AS (
    SELECT DATEADD(DAY, -30, CURRENT_DATE()) AS DATE_VAL
    UNION ALL
    SELECT DATEADD(DAY, 1, DATE_VAL)
    FROM date_range
    WHERE DATE_VAL < CURRENT_DATE()
)
SELECT DATE_VAL
FROM date_range
LIMIT 31;
```

#### ファネル分析CTE

```sql
WITH user_events AS (
    SELECT
        USER_ID,
        MIN(EVENT_TIMESTAMP) AS FIRST_EVENT_TIME,
        MAX(EVENT_TIMESTAMP) AS LAST_EVENT_TIME,
        COUNT(*) AS TOTAL_EVENTS
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY USER_ID
),

user_conversions AS (
    SELECT
        USER_ID,
        COUNT(CASE WHEN EVENT_TYPE = 'page_view' THEN 1 END) > 0 AS VIEWED_PAGE,
        COUNT(CASE WHEN EVENT_TYPE = 'add_to_cart' THEN 1 END) > 0 AS ADDED_TO_CART,
        COUNT(CASE WHEN EVENT_TYPE = 'checkout' THEN 1 END) > 0 AS STARTED_CHECKOUT,
        COUNT(CASE WHEN EVENT_TYPE = 'purchase' THEN 1 END) > 0 AS COMPLETED_PURCHASE
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY USER_ID
)

SELECT
    COUNT(*) AS TOTAL_USERS,
    SUM(CASE WHEN UC.VIEWED_PAGE THEN 1 ELSE 0 END) AS VIEWED_PAGE_USERS,
    SUM(CASE WHEN UC.ADDED_TO_CART THEN 1 ELSE 0 END) AS ADDED_TO_CART_USERS,
    SUM(CASE WHEN UC.STARTED_CHECKOUT THEN 1 ELSE 0 END) AS STARTED_CHECKOUT_USERS,
    SUM(CASE WHEN UC.COMPLETED_PURCHASE THEN 1 ELSE 0 END) AS COMPLETED_PURCHASE_USERS,
    ROUND(
        SUM(CASE WHEN UC.COMPLETED_PURCHASE THEN 1 ELSE 0 END)::FLOAT / COUNT(*), 4
    ) AS OVERALL_CONVERSION_RATE
FROM user_events UE
INNER JOIN user_conversions UC ON UE.USER_ID = UC.USER_ID;
```

#### CTEベストプラクティス

1. 論理的な順序で配置：基本データ取得 → 加工 → 集計 → 最終整形
2. 説明的な名前を使用：`WITH daily_purchase_summary AS (...)` ✓
3. 各CTEが独立実行可能になるよう設計
4. 3-5ステップを超える場合は分割を検討

---

### ステップ3：VIEW + DYNAMIC TABLE 設計（8分）

**目的**：VIEWとDYNAMIC TABLEの使い分けを習得

#### VIEW（リアルタイムデータ参照）

```sql
CREATE OR REPLACE VIEW V_EVENTS_WITH_USER_INFO AS
SELECT
    E.EVENT_ID, E.USER_ID, E.EVENT_TYPE, E.EVENT_TIMESTAMP, E.DEVICE_TYPE,
    U.COUNTRY, U.PLAN_TYPE, U.IS_ACTIVE,
    CASE
        WHEN U.PLAN_TYPE = 'premium' THEN 'Premium User'
        ELSE 'Free User'
    END AS USER_SEGMENT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U
    ON E.USER_ID = U.USER_ID;

SELECT * FROM V_EVENTS_WITH_USER_INFO
WHERE EVENT_TYPE = 'purchase'
LIMIT 20;
```

#### DYNAMIC TABLE（自動更新・パフォーマンス重視）

```sql
CREATE OR REPLACE DYNAMIC TABLE DT_DAILY_SUMMARY
  TARGET_LAG = '1 day'
  WAREHOUSE = COMPUTE_WH
AS
SELECT
    DATE(EVENT_TIMESTAMP) AS EVENT_DATE,
    COUNT(*) AS EVENT_COUNT,
    COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
    COUNT(DISTINCT CASE WHEN EVENT_TYPE = 'purchase' THEN EVENT_ID END) AS PURCHASE_COUNT
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP);
```

#### VIEW vs DYNAMIC TABLE 比較

| 項目 | VIEW | DYNAMIC TABLE |
|------|------|--------------|
| **ストレージ** | 不要 | 必要 |
| **データ鮮度** | リアルタイム | TARGET_LAGによる |
| **パフォーマンス** | 低い（毎回スキャン） | 高い（事前計算） |
| **用途** | リアルタイムデータ必須時 | 複雑集計をよく参照時 |

---

### ステップ4：SP + Task パイプライン構築（12分）

**目的**：実務規模のSP + Taskパイプラインの構築と課題の理解

#### パラメータ付きプロシジャ

```sql
CREATE OR REPLACE PROCEDURE SP_CALCULATE_BY_COUNTRY(P_COUNTRY VARCHAR)
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
BEGIN
    INSERT INTO DAILY_SUMMARY_BY_COUNTRY (
        EVENT_DATE, COUNTRY, EVENT_COUNT, UNIQUE_USERS, PURCHASE_COUNT
    )
    SELECT
        DATE(E.EVENT_TIMESTAMP) AS EVENT_DATE,
        :P_COUNTRY AS COUNTRY,
        COUNT(*) AS EVENT_COUNT,
        COUNT(DISTINCT E.USER_ID) AS UNIQUE_USERS,
        COUNT(DISTINCT CASE WHEN E.EVENT_TYPE = 'purchase' THEN E.EVENT_ID END) AS PURCHASE_COUNT
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS E
    INNER JOIN DIESELPJ_TEST.DBT_HANDSON.USERS U ON E.USER_ID = U.USER_ID
    WHERE U.COUNTRY = :P_COUNTRY
    GROUP BY DATE(E.EVENT_TIMESTAMP);

    RETURN 'Processing completed for: ' || :P_COUNTRY;
END;
$$;

CALL SP_CALCULATE_BY_COUNTRY('US');
CALL SP_CALCULATE_BY_COUNTRY('JP');
```

#### 統合パイプラインSP

```sql
CREATE OR REPLACE PROCEDURE SP_RUN_NIGHTLY_PIPELINE()
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
DECLARE
    v_step_1_rows INTEGER;
    v_step_2_rows INTEGER;
    v_step_3_rows INTEGER;
BEGIN
    -- ステップ1：日別集計テーブルを更新
    TRUNCATE TABLE DAILY_SUMMARY;
    INSERT INTO DAILY_SUMMARY (EVENT_DATE, EVENT_COUNT, UNIQUE_USERS)
    SELECT DATE(EVENT_TIMESTAMP), COUNT(*), COUNT(DISTINCT USER_ID)
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE(EVENT_TIMESTAMP);
    SELECT COUNT(*) INTO :v_step_1_rows FROM DAILY_SUMMARY;

    -- ステップ2：週別集計テーブルを更新
    TRUNCATE TABLE WEEKLY_SUMMARY;
    INSERT INTO WEEKLY_SUMMARY (WEEK_START, WEEK_END, EVENT_COUNT, UNIQUE_USERS, PURCHASE_COUNT)
    SELECT
        DATE_TRUNC('WEEK', EVENT_TIMESTAMP),
        DATEADD(DAY, 6, DATE_TRUNC('WEEK', EVENT_TIMESTAMP)),
        COUNT(*), COUNT(DISTINCT USER_ID),
        COUNT(DISTINCT CASE WHEN EVENT_TYPE = 'purchase' THEN EVENT_ID END)
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    GROUP BY DATE_TRUNC('WEEK', EVENT_TIMESTAMP);
    SELECT COUNT(*) INTO :v_step_2_rows FROM WEEKLY_SUMMARY;

    -- ステップ3：アクティブユーザーテーブルを更新
    TRUNCATE TABLE ACTIVE_USERS;
    INSERT INTO ACTIVE_USERS (USER_ID, LAST_EVENT_DATE, TOTAL_EVENTS)
    SELECT USER_ID, MAX(DATE(EVENT_TIMESTAMP)), COUNT(*)
    FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
    WHERE DATE(EVENT_TIMESTAMP) >= DATEADD(DAY, -30, CURRENT_DATE())
    GROUP BY USER_ID;
    SELECT COUNT(*) INTO :v_step_3_rows FROM ACTIVE_USERS;

    RETURN 'Step1: ' || :v_step_1_rows || ' rows, ' ||
           'Step2: ' || :v_step_2_rows || ' rows, ' ||
           'Step3: ' || :v_step_3_rows || ' rows.';
END;
$$;

CALL SP_RUN_NIGHTLY_PIPELINE();
```

#### エラーハンドリング

```sql
CREATE OR REPLACE PROCEDURE SP_SAFE_DATA_UPDATE()
RETURNS VARCHAR
LANGUAGE SQL
AS
$$
DECLARE
    v_error_message VARCHAR;
BEGIN
    BEGIN
        DELETE FROM DAILY_SUMMARY WHERE 1=1;

        INSERT INTO DAILY_SUMMARY (EVENT_DATE, EVENT_COUNT, UNIQUE_USERS)
        SELECT DATE(EVENT_TIMESTAMP), COUNT(*), COUNT(DISTINCT USER_ID)
        FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
        GROUP BY DATE(EVENT_TIMESTAMP);

        RETURN 'Data update completed successfully';

    EXCEPTION
        WHEN STATEMENT_ERROR THEN
            v_error_message := 'SQL Error occurred during data update';
            RETURN :v_error_message;
        WHEN OTHER THEN
            v_error_message := 'Unknown error occurred';
            RETURN :v_error_message;
    END;
END;
$$;
```

#### タスク依存関係（ファン・アウト構造）

```sql
-- 親タスク
CREATE OR REPLACE TASK TSK_ETL_CLEAN_EVENTS
WAREHOUSE = COMPUTE_WH
SCHEDULE = 'USING CRON 0 1 * * * UTC'
AS
DELETE FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
WHERE EVENT_TIMESTAMP IS NULL OR USER_ID IS NULL;

-- 子タスク1（日別集計）
CREATE OR REPLACE TASK TSK_ETL_DAILY_SUMMARY
WAREHOUSE = COMPUTE_WH
AFTER TSK_ETL_CLEAN_EVENTS
AS
INSERT INTO DAILY_SUMMARY (EVENT_DATE, EVENT_COUNT, UNIQUE_USERS)
SELECT DATE(EVENT_TIMESTAMP), COUNT(*), COUNT(DISTINCT USER_ID)
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
GROUP BY DATE(EVENT_TIMESTAMP);

-- 子タスク2（アクティブユーザー）
CREATE OR REPLACE TASK TSK_ETL_ACTIVE_USERS
WAREHOUSE = COMPUTE_WH
AFTER TSK_ETL_CLEAN_EVENTS
AS
INSERT INTO ACTIVE_USERS (USER_ID, LAST_EVENT_DATE, TOTAL_EVENTS)
SELECT USER_ID, MAX(DATE(EVENT_TIMESTAMP)), COUNT(*)
FROM DIESELPJ_TEST.DBT_HANDSON.RAW_EVENTS
WHERE DATE(EVENT_TIMESTAMP) >= DATEADD(DAY, -30, CURRENT_DATE())
GROUP BY USER_ID;
```

```
ファン・アウト構造：
  親 (TSK_ETL_CLEAN_EVENTS)
   ├─ 子1 (TSK_ETL_DAILY_SUMMARY)
   └─ 子2 (TSK_ETL_ACTIVE_USERS)
```

#### SP/Taskのメリット・デメリット

| 項目 | メリット | デメリット |
|------|---------|---------|
| **SP** | 複雑な処理を1つにまとめられる | テスト困難、デバッグ困難、Git管理が煩雑 |
| **Task** | 定期実行が容易、依存関係管理可能 | DAG管理が手動、エラー監視が必要 |

**重要**：2コマ目（dbt実践）では、このSP + Taskの課題をdbtで解決します。

---

### SQL応用まとめ（5分）

| ステップ | 学んだこと | SQLでの課題 |
|----------|-----------|-----------|
| **応用パターン** | FULL OUTER JOIN, Window関数 | 複雑になると管理が困難 |
| **CTE** | 複雑なクエリを段階化 | ファイル分割はできない |
| **VIEW/DT** | クエリの再利用 | 手動でCREATE/管理 |
| **SP + Task** | 処理のまとめ + 定期実行 | テスト困難、Git管理しにくい、依存管理が複雑 |

**SQL技術の使い分け判断基準**：

| ニーズ | 推奨技術 | 限界 |
|--------|---------|------|
| アドホック分析 | SELECT / CTE | 再利用困難 |
| 再利用可能クエリ | VIEW / DT | テスト困難 |
| 複雑ロジック | SP | Git管理困難 |
| 定期実行 | Task | DAG管理困難 |
| **上記すべて** | **dbt（次のコマ）** | — |

**次のコマ（dbt実践）では**、これらの課題をdbtがどう解決するかを体験します。

---

## 中級者コース・2コマ目：dbt実践（45分）

### ステップ5：Intermediate層の意義（10分）

**目的**：Staging → Intermediate → Marts の3層構造を理解する

#### 層の役割

| 層 | Materialization | 役割 | 例 |
|----|----------------|------|-----|
| **Staging** | VIEW | ソースデータの前処理 | stg_events, stg_users |
| **Intermediate** | VIEW | 複数テーブル結合、加工 | int_daily_events |
| **Marts** | TABLE | ビジネスユーザー向け最終テーブル | daily_summary |

#### int_daily_events.sql（中間モデル）

```sql
{{ config(materialized='view', tags=['intermediate']) }}

WITH events AS (
    SELECT * FROM {{ ref('stg_events') }}
),

users AS (
    SELECT * FROM {{ ref('stg_users') }}
),

joined_events AS (
    SELECT
        E.EVENT_DATE, E.EVENT_TYPE, E.FUNNEL_STAGE, E.DEVICE_TYPE,
        U.COUNTRY, U.PLAN_TYPE, U.USER_SEGMENT, U.COHORT,
        E.USER_ID, E.SESSION_ID, E.EVENT_ID
    FROM events E
    INNER JOIN users U ON E.USER_ID = U.USER_ID
),

daily_aggregated AS (
    SELECT
        EVENT_DATE, COUNTRY, PLAN_TYPE, USER_SEGMENT,
        COUNT(DISTINCT USER_ID) AS UNIQUE_USERS,
        COUNT(DISTINCT SESSION_ID) AS UNIQUE_SESSIONS,
        COUNT(EVENT_ID) AS TOTAL_EVENTS,
        COUNT(DISTINCT CASE WHEN EVENT_TYPE = 'PURCHASE' THEN EVENT_ID END) AS PURCHASE_EVENTS
    FROM joined_events
    GROUP BY EVENT_DATE, COUNTRY, PLAN_TYPE, USER_SEGMENT
)

SELECT * FROM daily_aggregated
```

**ref() の利点**：
- 依存関係をdbtが自動認識 → DAG（有向非巡回グラフ）生成
- モデル名変更時も自動で追跡
- 実行順序をdbtが自動決定

#### 実行

```bash
dbt run -s staging intermediate
```

---

### ステップ6：Macros（DRY原則）（10分）

**目的**：コード重複を排除し、保守性を向上する

#### マクロとは

複数のモデルで同じロジックを使う場合に、**1箇所で定義して使い回す**仕組みです。

#### funnel_stage_generator マクロ

```sql
-- macros/common_logic.sql
{% macro funnel_stage_generator(event_type_col) %}
    CASE
        WHEN {{ event_type_col }} = 'PAGE_VIEW' THEN 'Engagement'
        WHEN {{ event_type_col }} IN ('CLICK', 'ADD_TO_CART') THEN 'Consideration'
        WHEN {{ event_type_col }} IN ('CHECKOUT', 'PURCHASE') THEN 'Conversion'
        WHEN {{ event_type_col }} = 'SIGN_UP' THEN 'Acquisition'
        ELSE 'Other'
    END
{% endmacro %}
```

#### モデルでの使用例（stg_events.sql）

```sql
SELECT
    EVENT_ID,
    USER_ID,
    UPPER(EVENT_TYPE) AS EVENT_TYPE,
    {{ funnel_stage_generator('UPPER(EVENT_TYPE)') }} AS FUNNEL_STAGE
FROM {{ source('analytics', 'RAW_EVENTS') }}
```

#### その他のマクロ例

```sql
-- ユーザーセグメント生成
{% macro user_segment_generator(plan_type_col, is_active_col) %}
    CASE
        WHEN {{ plan_type_col }} = 'premium' AND {{ is_active_col }} = TRUE THEN 'Premium Active'
        WHEN {{ plan_type_col }} = 'premium' AND {{ is_active_col }} = FALSE THEN 'Premium Inactive'
        WHEN {{ plan_type_col }} = 'free' AND {{ is_active_col }} = TRUE THEN 'Free Active'
        ELSE 'Free Inactive'
    END
{% endmacro %}

-- コンバージョンレート計算（0除算回避）
{% macro conversion_rate_calculator(numerator, denominator, decimal_places=4) %}
    ROUND({{ numerator }}::FLOAT / NULLIF({{ denominator }}, 0), {{ decimal_places }})
{% endmacro %}
```

#### マクロのメリット

| 観点 | マクロなし（コピペ） | マクロあり（DRY） |
|------|---------------------|-------------------|
| **変更時** | 全ファイルを修正 | 1箇所修正で全反映 |
| **バグ混入** | コピペ漏れでバグ | 1箇所なのでバグなし |
| **可読性** | 同じCASE文が散在 | マクロ名で意図が明確 |

---

### ステップ7：Weekly Summary + Window関数（10分）

**目的**：Martsモデルの応用と前週比計算

#### weekly_summary.sql

```sql
{{ config(materialized='table', tags=['marts']) }}

WITH daily AS (
    SELECT * FROM {{ ref('daily_summary') }}
),

weekly_aggregated AS (
    SELECT
        DATE_TRUNC('WEEK', EVENT_DATE) AS WEEK_START_DATE,
        COUNTRY,
        PLAN_TYPE,
        SUM(UNIQUE_USERS) AS TOTAL_WEEKLY_USERS,
        SUM(TOTAL_EVENTS) AS TOTAL_WEEKLY_EVENTS,
        SUM(PURCHASE_EVENTS) AS TOTAL_WEEKLY_PURCHASES,
        {{ conversion_rate_calculator('SUM(PURCHASE_EVENTS)', 'SUM(UNIQUE_USERS)') }} AS PURCHASE_RATE
    FROM daily
    GROUP BY DATE_TRUNC('WEEK', EVENT_DATE), COUNTRY, PLAN_TYPE
),

with_wow AS (
    SELECT
        *,
        LAG(TOTAL_WEEKLY_EVENTS) OVER (
            PARTITION BY COUNTRY, PLAN_TYPE ORDER BY WEEK_START_DATE
        ) AS PREV_WEEK_EVENTS,
        {{ wow_change_calculator(
            'TOTAL_WEEKLY_EVENTS',
            'LAG(TOTAL_WEEKLY_EVENTS) OVER (PARTITION BY COUNTRY, PLAN_TYPE ORDER BY WEEK_START_DATE)'
        ) }} AS WOW_EVENT_CHANGE
    FROM weekly_aggregated
)

SELECT * FROM with_wow
```

#### 実行

```bash
dbt run -s weekly_summary
```

---

### ステップ8：高度テスト + ドキュメント生成（10分）

**目的**：ビジネスロジックの品質保証とドキュメント自動化

#### 基本テスト（初心者コースで学習済み）

```yaml
tests:
  - unique       # 一意性
  - not_null     # NULL非許容
```

#### 高度テスト（dbt_utils パッケージ）

```yaml
# tests/schema.yml
- name: daily_summary
  columns:
    - name: PURCHASE_RATE
      tests:
        - dbt_utils.accepted_range:
            min_value: 0
            max_value: 1
    - name: UNIQUE_USERS
      tests:
        - dbt_utils.accepted_range:
            min_value: 0
  tests:
    - dbt_utils.unique_combination_of_columns:
        combination_of_columns:
          - EVENT_DATE
          - COUNTRY
          - PLAN_TYPE
          - USER_SEGMENT
```

**高度テストの種類**：

| テスト | 用途 | 例 |
|--------|------|-----|
| `accepted_range` | 値の範囲チェック | レートは0〜1 |
| `unique_combination_of_columns` | 複合キーの一意性 | 日付+国+プランの組み合わせ |
| `relationships` | 外部キー参照整合性 | SESSION.USER_ID → USERS.USER_ID |
| `accepted_values` | 許容値リスト | event_type が定義値のみ |

#### ドキュメント生成

```bash
dbt docs generate
```

**生成内容**：
- モデルのスキーマ情報
- テーブル・カラムの説明
- **Lineage DAG**（データの系譜）
- テスト定義

#### Lineageの価値

```
RAW_EVENTS → stg_events → int_daily_events → daily_summary → weekly_summary
                                  ↑
USERS      → stg_users   ────────┘
```

- データの流れを可視化
- 影響分析（どのモデルを変更したら何が変わるか）
- 新人研修が容易

---

### SP+Task → dbt 置き換え比較（5分）

**目的**：1コマ目で学んだ SP+Task の課題を、dbt がどう解決するか

#### SQL版の課題

```sql
-- ストアドプロシジャの問題
CREATE PROCEDURE SP_RUN_NIGHTLY_PIPELINE() AS
BEGIN
    -- ステップ1：日別集計
    DELETE FROM DAILY_SUMMARY;
    INSERT INTO DAILY_SUMMARY ...;
    -- ステップ2：週別集計
    DELETE FROM WEEKLY_SUMMARY;
    INSERT INTO WEEKLY_SUMMARY ...;
END;

-- タスクで定期実行
CREATE TASK TSK_NIGHTLY SCHEDULE = 'USING CRON 0 1 * * * UTC'
AS CALL SP_RUN_NIGHTLY_PIPELINE();
```

#### dbt版での解決

```bash
# 1コマンドで全モデル実行（依存順序は自動）
dbt run

# テストも1コマンド
dbt test
```

#### 比較表

| 項目 | SP + Task | dbt |
|------|-----------|-----|
| **テスト性** | 困難 | `dbt test` で自動 |
| **ドキュメント** | 手動 | `dbt docs generate` で自動 |
| **Git連携** | 弱い | 完全統合 |
| **保守性** | 低い（巨大SP） | 高い（モデル分割） |
| **再利用性** | 低い | 高い（Macros） |
| **デバッグ** | 困難 | 容易（モデル単位で実行） |
| **依存管理** | 手動（AFTER句） | 自動（ref()） |

---

### 中級者コースのまとめ

| 学んだこと | SQLの課題 | dbtでの解決 |
|-----------|----------|------------|
| **Intermediate層** | CTEが長大化 | モデル分割で可読性向上 |
| **Macros** | コピペでロジック散在 | 1箇所定義で全モデル反映 |
| **高度テスト** | 手動SQLで検証 | schema.yml + dbt test |
| **ドキュメント** | 手動作成・陳腐化 | 自動生成・常に最新 |
| **パイプライン** | SP+Task で複雑 | `dbt run` で簡潔 |

---

## 実務での推奨アーキテクチャ

```
Raw Data (S3/API)
    ↓
[dbt Staging] → Snowflake RAW_EVENTS
    ↓
[dbt Intermediate] → Snowflake INTERMEDIATE
    ↓
[dbt Marts] → Snowflake MARTS
    ↓
BI ツール（Tableau, Looker等）
    ↓
ビジネスダッシュボード
```

### SQLとdbtの使い分け

#### SQLを使う場面
- データの初期確認（SELECT, WHERE, DISTINCT）
- アドホック分析
- シンプルな処理

#### dbtを使う場面（推奨）
- 定期的に実行するパイプライン
- 複数モデルの組み合わせ
- テスト・品質管理が重要
- チーム開発
- バージョン管理が必須

---

## 次のステップ（学習リソース）

1. **dbt公式ドキュメント** - https://docs.getdbt.com
2. **dbt Learn** - 無料オンラインコース
3. **dbt Slack コミュニティ** - 質問・相談の場
4. **Snowflake + dbt連携** - Snowflake dbt Integration ガイド
5. **高度なトピック** - Dynamic Tables、dbt Metrics、dbt Cloud

---

## Q&A想定集

### Q1：初心者コースと中級者コース、どちらから始めるべき？

**A**：SQLの経験で判断してください：
- **SQL未経験** → 初心者コースから
- **SELECT, JOIN, GROUP BYがわかる** → 中級者コースから
- **不安な場合** → 初心者コースから始めて、中級者コースに進むのがおすすめ

### Q2：dbtは必須ですか？

**A**：小規模プロジェクト（<100万行/日）であれば、Snowflake Taskで十分です。
ただし以下の場合はdbt推奨：
- チーム開発
- テスト・品質管理が重要
- 複雑な変換ロジック
- 将来の拡張を見据えている

### Q3：既存のストアドプロシジャはどうする？

**A**：段階的に移行してください：
1. 新規パイプライン → dbtで実装
2. 既存パイプライン → 優先度高いものから dbt に移行
3. 古いプロシジャ → 廃止

### Q4：パフォーマンスはどちらが良い？

**A**：同等です。以下に注意：
- 不要なカラムは SELECT しない（SQL, dbt両方）
- JOINの順序を最適化（dbtも Snowflake が自動最適化）
- インデックス活用（Snowflakeでは CLUSTERING キー）

### Q5：Incremental modelはいつ使う？

**A**：以下の条件下：
- **大規模データ**（100万件/日以上）
- **増分処理が可能**（タイムスタンプで差分判定可能）
- **パフォーマンスが重要**（毎日の実行時間が問題）

### Q6：テストはどのくらい詳細に書く？

**A**：最初は基本テスト：
- 主キー： `unique`
- 必須フィールド： `not_null`
- 分類値： `accepted_values`

詳細テストは後から追加：
- データ範囲チェック（0-100%等）
- 外部キー検証
- 業務ルール検証

### Q7：dbtクラウドは必須？

**A**：いいえ。以下で選択：
- **dbt Cloud（有料）** → UI操作、スケジューリング機能充実
- **dbt on Snowflake（無料）** → Git統合、Snowflake UI で十分
- **ローカル dbt CLI（無料）** → 開発時のみ

### Q8：本番環境での実行頻度は？

**A**：ビジネス要件によりますが、一般的には：
- **リアルタイム関連**（ユーザー行動） → 1時間ごと
- **日次レポート** → 毎日深夜
- **週次分析** → 毎週月曜朝
- **月次決算** → 月初

### Q9：他のDBMS（PostgreSQL, BigQuery等）でも使える？

**A**：はい。dbtは複数DBMS対応：
- Snowflake（推奨）
- PostgreSQL
- BigQuery
- Redshift
- Databricks

ただしSnowflake固有の機能（Dynamic Tables, Clustering等）は未対応。

---

## 補足：ベストプラクティス

### SQLベストプラクティス

1. **必要なカラムのみ SELECT**
2. **フィルタリングは早期に**（WHERE句をJOIN前に）
3. **複雑なロジックはCTEで分割**
4. **GROUP BYにない列をSELECTしない**

### dbtベストプラクティス

1. **モデル名は層を示す** - `stg_`、`int_`、`fct_`、`dim_`
2. **テストは必須** - `unique`、`not_null`、`accepted_values`
3. **ドキュメント必須** - `description` を全モデル・全カラムに
4. **Macros で再利用** - 同じロジックは2回書かない

---

**質問・フィードバックは随時受け付けています。**
